{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.648 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "prefix = './data_ch/'\n",
    "\n",
    "train = []\n",
    "files = ['train.0']\n",
    "for file_item in files:\n",
    "    with open(prefix+file_item, 'r') as f:\n",
    "        for item in f:\n",
    "            d = {}\n",
    "            d['label'] = 0\n",
    "            d['text'] = \" \".join(jieba.cut(item.strip().replace(\"臺\", \"台\"), cut_all=False))\n",
    "            train.append(d)\n",
    "files = ['train.1']\n",
    "for file_item in files:\n",
    "    with open(prefix+file_item, 'r') as f:\n",
    "        for item in f:\n",
    "            d = {}\n",
    "            d['label'] = 1\n",
    "            d['text'] = \" \".join(jieba.cut(item.strip().replace(\"臺\", \"台\"), cut_all=False))\n",
    "            train.append(d)\n",
    "\n",
    "valid = []\n",
    "files = ['dev.0']\n",
    "for file_item in files:\n",
    "    with open(prefix+file_item, 'r') as f:\n",
    "        for item in f:\n",
    "            d = {}\n",
    "            d['label'] = 0\n",
    "            d['text'] = \" \".join(jieba.cut(item.strip().replace(\"臺\", \"台\"), cut_all=False))\n",
    "            valid.append(d)\n",
    "files = ['dev.1']\n",
    "for file_item in files:\n",
    "    with open(prefix+file_item, 'r') as f:\n",
    "        for item in f:\n",
    "            d = {}\n",
    "            d['label'] = 1\n",
    "            d['text'] = \" \".join(jieba.cut(item.strip().replace(\"臺\", \"台\"), cut_all=False))\n",
    "            valid.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906 2488\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': '然而 在 當前 的 政治 環境 下 ， 制憲權 的 行使 ， 卻 被 視為 破壞 憲政 秩序 的 行為 ， 無怪乎 國軍將 領會 拒斥 新憲法 的 產生 ， 惟 就 各國 憲政 發展 史觀 之'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[-31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/cealia312/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "SENT_DETECTOR = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import re \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(s):\n",
    "    return s.split()\n",
    "\n",
    "def collect_words(data, n_workers): #collect training, valid words\n",
    "    sent_list = []\n",
    "    for i in data:\n",
    "        sent_list.extend(i['text'].split('\\n'))\n",
    "        \n",
    "    chunks = \\\n",
    "    [' '.join(sent_list[i: i+len(sent_list)//n_workers]) for i in range(0, len(sent_list), len(sent_list)//n_workers)]\n",
    "    \n",
    "    with Pool(n_workers) as pool:\n",
    "        chunks = pool.map_async(get_tokens, chunks)\n",
    "        words = set(sum(chunks.get(), []))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect train words...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8278549fd4fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Collect train words...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcollect_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Collect valid words...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcollect_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "words = set()\n",
    "print('Collect train words...')\n",
    "words |= collect_words(train, n_workers=6)\n",
    "print('Collect valid words...')\n",
    "words |= collect_words(valid, n_workers=6)\n",
    "# print('Collect test words...')\n",
    "# words |= collect_words(test, n_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46064"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_words = set()\n",
    "\n",
    "# for word in words:\n",
    "#     word = word.lower()\n",
    "#     lower_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_words = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213549"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(lower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['<pad>', '<unk>', '<sos>', '<eos>']:\n",
    "    lower_words.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46068"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2196017/2196017 [00:46<00:00, 47564.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# used_glove = {}\n",
    "# from_glove = 0\n",
    "# with open('glove.840B.300d.txt') as fp:\n",
    "#     row1 = fp.readline()\n",
    "#     # if the first row is not header\n",
    "#     if not re.match('^[0-9]+ [0-9]+$', row1):\n",
    "#         # seek to 0\n",
    "#         fp.seek(0)\n",
    "#     # otherwise ignore the header\n",
    "\n",
    "#     for i, line in tqdm(enumerate(fp), total=2196017):\n",
    "#         cols = line.rstrip().split(' ')\n",
    "#         word = cols[0].lower()\n",
    "        \n",
    "#         if word in lower_words:\n",
    "#             from_glove += 1\n",
    "#             used_glove[word] = [float(v) for v in cols[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146865"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(used_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_glove = {}\n",
    "# special_tokens = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "for t in lower_words:\n",
    "#     if t not in used_glove:\n",
    "        used_glove[t] = np.random.normal(scale=0.6, size=(256, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46068"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix = list(used_glove.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46068, 256)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix = np.asarray(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46068, 256)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46068/46068 [00:00<00:00, 1404054.68it/s]\n"
     ]
    }
   ],
   "source": [
    "word2id = {}\n",
    "id2word = {}\n",
    "# words_found = 0\n",
    "\n",
    "for i, word in tqdm(enumerate(used_glove.keys()), total=len(used_glove)):\n",
    "    word2id[word] = i\n",
    "    id2word[i] = word\n",
    "#     try: \n",
    "#         weights_matrix[i] = used_glove[word]\n",
    "#         words_found += 1\n",
    "#     except KeyError:\n",
    "#         weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16183\n",
      "44230\n",
      "15134\n",
      "16044\n"
     ]
    }
   ],
   "source": [
    "for i in ['<pad>', '<unk>', '<sos>', '<eos>']:\n",
    "    print(word2id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213553, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights_matrix.shape (213553, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# prefix = 'word_dict_ch/'\n",
    "# os.mkdir(prefix)\n",
    "# with open(prefix+'word2id.json', 'w') as f:\n",
    "#     json.dump(word2id, f)\n",
    "    \n",
    "# with open(prefix+'id2word.json', 'w') as f:\n",
    "#     json.dump(id2word, f)\n",
    "    \n",
    "# with open(prefix+'weights_matrix.pkl','wb') as f:\n",
    "#     pickle.dump(weights_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_dict_ch/word2id.json', 'r') as f:\n",
    "    word2id = json.load(f)\n",
    "    \n",
    "with open('word_dict_ch/id2word.json', 'r') as f:\n",
    "    id2word = json.load(f)\n",
    "    \n",
    "with open('word_dict_ch/weights_matrix.pkl','rb') as f:\n",
    "    weights_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46068, 256)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor as P\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = './data/'\n",
    "# train = []\n",
    "# files = ['democratic_only.train.en', 'republican_only.train.en']\n",
    "# for file_item in files:\n",
    "#     with open(prefix+file_item, 'r') as f:\n",
    "#         for item in f:\n",
    "#             item = item.strip()\n",
    "#             train.append(item)\n",
    "# #             word_list = nltk.word_tokenize(item)\n",
    "# #             for word in word_list:\n",
    "# #                 word = word.lower()\n",
    "# #                 if word not in word_to_id:\n",
    "# #                     word_to_id[word] = 0\n",
    "# #                 word_to_id[word] += 1\n",
    "# prefix = './data/'\n",
    "# valid = []\n",
    "# files = ['democratic_only.dev.en', 'republican_only.dev.en']\n",
    "# for file_item in files:\n",
    "#     with open(prefix+file_item, 'r') as f:\n",
    "#         for item in f:\n",
    "#             item = item.strip()\n",
    "#             valid.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 0,\n",
       "  'text': '9 年 ， 面對 複 雜嚴峻 的 台海 形勢 ， 我們 深入 貫徹習 近平 總書記 在 《 告台灣 同胞 書 》 發表 40 週年 紀念會 上 的 重要 講話 和 黨 的 十九 屆 四中 全會 精神'},\n",
       " {'label': 0,\n",
       "  'text': '9 年 ， 廣大台灣 同胞 對 加強 兩岸 交流 合作 的 期待 與民 進黨 當局 的 限制 打壓 形成 了 強烈 對 比 ； 兩岸 人員往 來 、 各 領域 交流 合作 發展 的 勢頭 與 民進 黨 當局 的 倒行逆施 形成 了 強烈 反差'},\n",
       " {'label': 0,\n",
       "  'text': '續 出台 關於進 一步 促進 兩岸 經濟 文化交流 合作 的 一系列 政策措施 ， 為 台灣 同胞 來大陸 學習 、 工作 、 生活 提供 更 多 的 便利 ， 積極 鼓勵 、 支援 兩岸民間 各 領域 的 交流 合作'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(data, n):\n",
    "    for i in range(0, len(data), n):\n",
    "        yield data[i:i+n]\n",
    "        \n",
    "def raw2processed(data):\n",
    "    processed_data = []\n",
    "    \n",
    "    for d in data:\n",
    "        item = {}\n",
    "        #item['id'] = d['id']\n",
    "        item['text'] = []\n",
    "        item['label'] = d['label']\n",
    "        for w in d['text'].split():\n",
    "            #w = w.lower()\n",
    "            if w in word2id:\n",
    "                item['text'].append(word2id[w])\n",
    "            else:\n",
    "                item['text'].append(word2id['<unk>'])\n",
    "                \n",
    "        processed_data.append(item)\n",
    "    return processed_data\n",
    "                    \n",
    "def preprocessed_ls(num_worker, raw_data):\n",
    "    chunked_data = list(chunk(raw_data, 100))\n",
    "\n",
    "    with P(max_workers=num_worker) as executor:\n",
    "        r = executor.map(raw2processed, chunked_data)\n",
    "    ls_r = list(r)\n",
    "    return [item for ls in ls_r for item in ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess training corpus to indexes...\n",
      "Preprocess valid corpus to indexes...\n"
     ]
    }
   ],
   "source": [
    "print('Preprocess training corpus to indexes...')\n",
    "train_ls = preprocessed_ls(num_worker=4, raw_data=train)\n",
    "print('Preprocess valid corpus to indexes...')\n",
    "valid_ls = preprocessed_ls(num_worker=4, raw_data=valid)\n",
    "# print('Preprocess testing corpus to indexes...')\n",
    "# test_ls = preprocessed_ls(num_worker=8, raw_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 0, 'text': '9 年 ， 面對 複 雜嚴峻 的 台海 形勢 ， 我們 深入 貫徹習 近平 總書記 在 《 告台灣 同胞 書 》 發表 40 週年 紀念會 上 的 重要 講話 和 黨 的 十九 屆 四中 全會 精神'} {'text': [21182, 10148, 7519, 12807, 23901, 520, 28393, 45498, 38522, 7519, 5140, 6745, 428, 5283, 31723, 3017, 18306, 32870, 7405, 12688, 11309, 13839, 28678, 40429, 18290, 1802, 28393, 12113, 16362, 23066, 24107, 28393, 19082, 16135, 36019, 1568, 39836], 'label': 0}\n",
      "{'label': 0, 'text': '9 年 ， 廣大台灣 同胞 對 加強 兩岸 交流 合作 的 期待 與民 進黨 當局 的 限制 打壓 形成 了 強烈 對 比 ； 兩岸 人員往 來 、 各 領域 交流 合作 發展 的 勢頭 與 民進 黨 當局 的 倒行逆施 形成 了 強烈 反差'} ['9', '年', '，', '廣大台灣', '同胞', '對', '加強', '兩岸', '交流', '合作', '的', '期待', '與民', '進黨', '當局', '的', '限制', '打壓', '形成', '了', '強烈', '對', '比', '；', '兩岸', '人員往', '來', '、', '各', '領域', '交流', '合作', '發展', '的', '勢頭', '與', '民進', '黨', '當局', '的', '倒行逆施', '形成', '了', '強烈', '反差']\n"
     ]
    }
   ],
   "source": [
    "print(train[0], train_ls[0])\n",
    "print(train[1], [id2word[str(id_)] for id_ in train_ls[1]['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906 2488\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ls), len(valid_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article_Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):#每次怎麼讀數據\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(datas): #整理func -> batch = [(),(),]\n",
    "    batch_text = []\n",
    "#     batch_id = []\n",
    "#     batch_summary = []\n",
    "    batch_label = []\n",
    "\n",
    "    for data in datas:\n",
    "        text_max_len=80\n",
    "        pad_text = []\n",
    "        if len(data['text']) >= text_max_len-2:\n",
    "            pad_text.append([word2id['<sos>']] + data['text'][:text_max_len-2] + [word2id['<eos>']])\n",
    "        else:\n",
    "            pad_text.append\\\n",
    "            ([word2id['<sos>']] + data['text'][:len(data['text'])] + \\\n",
    "             [word2id['<eos>']] + [word2id['<pad>']]*(text_max_len-len(data['text'])-2))\n",
    "        batch_text.extend(pad_text)\n",
    "        #label\n",
    "        batch_label.append(data['label'])\n",
    "#         #summary=30\n",
    "#         if 'summary' in data:\n",
    "#             pad_sum = []\n",
    "#             if len(data['summary']) >= 28:\n",
    "#                 pad_sum.append([word2id['<sos>']] + data['summary'][:30-2] + [word2id['<eos>']])\n",
    "#             else:\n",
    "#                 pad_sum.append\\\n",
    "#                 ([word2id['<sos>']] + data['summary'] + \\\n",
    "#                  [word2id['<eos>']] + [word2id['<pad>']]*(30-len(data['summary'])-2))\n",
    "#             batch_summary.extend(pad_sum)\n",
    "#         else:\n",
    "#             batch_summary.append([word2id['<sos>']]*30)\n",
    "    return torch.LongTensor(batch_text), torch.tensor(batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Article_Dataset(train_ls)\n",
    "validset = Article_Dataset(valid_ls)\n",
    "# testset = Article_Dataset(test_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_trainset = DataLoader(trainset, batch_size=2, shuffle=True, num_workers=0, \\\n",
    "                            collate_fn=lambda x:collate_fn(x))\n",
    "# batched_testset = DataLoader(testset, batch_size=2, shuffle=False, num_workers=0, \\\n",
    "#                             collate_fn=lambda x:collate_fn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15134, 34276, 13867, 18556, 28393, 43125, 15923, 28393, 27352, 42247,\n",
       "           5051,  9473, 44624, 28393, 19947,  7519, 31902, 35328,  7519, 43125,\n",
       "          15923,  6174, 32728, 13381,  7519,  3017, 32557, 10837, 40456,  7519,\n",
       "          29981, 37874, 19532, 26364, 13565, 36421, 16146, 18748,  7363, 28393,\n",
       "          16044, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183,\n",
       "          16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183,\n",
       "          16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183,\n",
       "          16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183],\n",
       "         [15134,  6382,  3017, 26164, 36530, 31250, 33824, 20934, 35438, 38249,\n",
       "           7519,   892, 16146, 33824, 28083, 18723, 38249, 28393, 25877, 25277,\n",
       "           7519, 36765, 45837, 42770, 17466, 28393,  9558, 22009,  2684, 26164,\n",
       "          23119,  6833, 28393, 17059, 21388, 16044, 16183, 16183, 16183, 16183,\n",
       "          16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183,\n",
       "          16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183,\n",
       "          16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183,\n",
       "          16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183, 16183]]),\n",
       " tensor([0, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(batched_trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next(iter(batched_testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "True True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available(), torch.backends.cudnn.enabled)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    '''\n",
    "    1. get word embedding \n",
    "    2. encaptulate Encoder and Decoder\n",
    "    '''\n",
    "    def __init__(self, weight_matrix, encoder, decoder):\n",
    "        super().__init__()\n",
    "        word_num, input_size = weight_matrix.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weight_matrix))\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, input_indexes, output_indexes, teacher_forcing):\n",
    "        batch_size, output_seq_len = output_indexes.shape\n",
    "        \n",
    "        input_ = self.embedding(input_indexes) #input_=(batch_size, input_len, input_size)\n",
    "        pre_hid = self.encoder(input_) #pre_hid=(num_layers * num_directions, batch_size, hidden_size)\n",
    "        latent = pre_hid.clone().detach().squeeze() #latent=(batch_size, hidden_size)\n",
    "        decoder_input = self.embedding(output_indexes[:,0])\n",
    "        decoder_input = decoder_input.unsqueeze(1) #input_len=1\n",
    "        \n",
    "        output = torch.zeros(output_seq_len, batch_size, self.embedding.num_embeddings).to(device)\n",
    "        output_2 = torch.zeros(output_seq_len, batch_size).to(device)\n",
    "        for i in range(1, output_seq_len):\n",
    "            word_dist, pre_hid = self.decoder(decoder_input, pre_hid)\n",
    "            word_indexes = torch.argmax(word_dist, dim=1)\n",
    "            output[i] = word_dist\n",
    "            output_2[i] = word_indexes\n",
    "            \n",
    "            if random.random()>=teacher_forcing: #if teacher_forcing==0, turn off \n",
    "                decoder_input = self.embedding(word_indexes)\n",
    "            else:\n",
    "                decoder_input = self.embedding(output_indexes[:, i])\n",
    "            decoder_input = decoder_input.unsqueeze(1)\n",
    "        \n",
    "        output_2 = torch.transpose(output_2, 0, 1)\n",
    "        return output, output_2, latent\n",
    "    \n",
    "    def encode(self, input_indexes):\n",
    "        input_ = self.embedding(input_indexes) #input_=(batch_size, input_len, input_size)\n",
    "        pre_hid = self.encoder(input_) #pre_hid=(num_layers * num_directions, batch_size, hidden_size)\n",
    "        latent = pre_hid.clone().detach().squeeze() #latent=(batch_size, hidden_size)\n",
    "        return latent\n",
    "    \n",
    "    def decode(self, output_indexes, latent): #teacher_forcing=0\n",
    "        pre_hid = latent.unsqueeze(0)\n",
    "        batch_size, output_seq_len = output_indexes.shape\n",
    "        \n",
    "        decoder_input = self.embedding(output_indexes[:,0])\n",
    "        decoder_input = decoder_input.unsqueeze(1) #input_len=1\n",
    "        \n",
    "        output = torch.zeros(output_seq_len, batch_size, self.embedding.num_embeddings).to(device)\n",
    "        output_2 = torch.zeros(output_seq_len, batch_size).to(device)\n",
    "        for i in range(1, output_seq_len):\n",
    "            word_dist, pre_hid = self.decoder(decoder_input, pre_hid)\n",
    "            word_indexes = torch.argmax(word_dist, dim=1)\n",
    "            output[i] = word_dist\n",
    "            output_2[i] = word_indexes\n",
    "            \n",
    "            decoder_input = self.embedding(output_indexes[:, i])\n",
    "            decoder_input = decoder_input.unsqueeze(1)\n",
    "            \n",
    "        output_2 = torch.transpose(output_2, 0, 1)\n",
    "        return output, output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    encode the whole input sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hid_size, num_layers, bidirectional):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(input_size, hid_size, num_layers, batch_first=True, bidirectional=bool(bidirectional))\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        output, h_n = self.rnn(input_) \n",
    "        #input_=(batch_size, seq_len, feature) \n",
    "        #h_0=(num_layers * num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        #output=(batch_size, seq_len, num_directions * hidden_size)\n",
    "        #h_n=(num_layers * num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        return h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    dose a single step of decoding\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hid_size, num_layers, bidirectional, word_num):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(input_size, hid_size, num_layers, batch_first=True, bidirectional=bool(bidirectional))\n",
    "        self.lr = nn.Linear((bidirectional+1)*hid_size, word_num)\n",
    "    \n",
    "    def forward(self, input_, pre_hid):\n",
    "        output, h_n = self.rnn(input_, pre_hid)\n",
    "        #input_=(batch_size, seq_len, feature) \n",
    "        #h_0=(num_layers * num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        #output=(batch_size, seq_len, num_directions * hidden_size)\n",
    "        #h_n=(num_layers * num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        word_dist = self.lr(output.squeeze(1))\n",
    "        return word_dist, h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, latent_size, class_num):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(latent_size, 100)\n",
    "        self.relu1 = nn.LeakyReLU(0.3)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.relu2 = nn.LeakyReLU(0.2)\n",
    "        self.fc3 = nn.Linear(50, class_num)\n",
    "\n",
    "    def forward(self, input): #input=(batch_size, hidden_size)\n",
    "        out = self.fc1(input)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out  # batch_size * label_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(2, 2, requires_grad=True)\n",
    "# y = x.clone().detach()\n",
    "# # y.retain_grad()\n",
    "# # y.requires_grad = True\n",
    "\n",
    "# z = y**2\n",
    "# z.mean().backward()\n",
    "\n",
    "# print(y.grad)\n",
    "# print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_num, emb_dim = weights_matrix.shape\n",
    "encoder = Encoder(input_size=256, hid_size=256, num_layers=1, bidirectional=0)\n",
    "decoder = Decoder(input_size=256, hid_size=256, num_layers=1, bidirectional=0, word_num=word_num)\n",
    "model = Seq2Seq(weight_matrix=weights_matrix, encoder=encoder, decoder=decoder)\n",
    "classifier = Classifier(latent_size=256, class_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_ch/model_1.pt'))\n",
    "classifier.load_state_dict(torch.load('model_ch/cls_1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (embedding): Embedding(46068, 256)\n",
      "  (encoder): Encoder(\n",
      "    (rnn): GRU(256, 256, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (rnn): GRU(256, 256, batch_first=True)\n",
      "    (lr): Linear(in_features=256, out_features=46068, bias=True)\n",
      "  )\n",
      ")\n",
      "Classifier(\n",
      "  (fc1): Linear(in_features=256, out_features=100, bias=True)\n",
      "  (relu1): LeakyReLU(negative_slope=0.2)\n",
      "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (relu2): LeakyReLU(negative_slope=0.2)\n",
      "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "classifier.to(device)\n",
    "print(model)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight Parameter containing:\n",
      "tensor([[ 0.2723,  0.0410, -0.4631,  ..., -0.0617, -0.0115,  0.1427],\n",
      "        [-1.1988,  0.1730,  0.5648,  ..., -0.1958, -0.6262,  0.3177],\n",
      "        [-0.4548, -0.0784, -0.3080,  ...,  0.0450,  0.7476,  0.8364],\n",
      "        ...,\n",
      "        [-0.5624, -0.5748,  0.7006,  ..., -0.1694,  0.4826,  0.0705],\n",
      "        [ 0.3107, -0.1274, -0.1226,  ..., -0.3409,  0.5496, -0.4199],\n",
      "        [-0.2818, -1.4297, -0.3846,  ..., -0.7473, -0.4242,  0.5158]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "encoder.rnn.weight_ih_l0 Parameter containing:\n",
      "tensor([[-0.0038,  0.0264, -0.1779,  ..., -0.0441, -0.0586, -0.0453],\n",
      "        [ 0.0290, -0.0666, -0.1162,  ...,  0.0242,  0.0197,  0.0008],\n",
      "        [ 0.1801, -0.0587, -0.0035,  ...,  0.2067, -0.1527, -0.0127],\n",
      "        ...,\n",
      "        [-0.0162,  0.0944, -0.0278,  ...,  0.0022,  0.0382, -0.0462],\n",
      "        [-0.0375, -0.2420,  0.0680,  ..., -0.0404,  0.0764, -0.1142],\n",
      "        [ 0.0688,  0.0933, -0.0431,  ...,  0.0934, -0.0938,  0.0586]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "encoder.rnn.weight_hh_l0 Parameter containing:\n",
      "tensor([[ 0.0962, -0.1558, -0.0863,  ...,  0.1005, -0.0241, -0.0306],\n",
      "        [-0.0377,  0.0658, -0.0564,  ...,  0.0598, -0.1214, -0.0253],\n",
      "        [-0.1073, -0.1317, -0.0419,  ...,  0.0952, -0.0046,  0.0946],\n",
      "        ...,\n",
      "        [ 0.0258,  0.0595,  0.0714,  ...,  1.0396, -0.0101,  0.0373],\n",
      "        [-0.1100,  0.0363,  0.1467,  ...,  0.1024,  0.1178,  0.0170],\n",
      "        [ 0.0148, -0.2085, -0.0173,  ..., -0.0011,  0.0140,  0.2797]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "encoder.rnn.bias_ih_l0 Parameter containing:\n",
      "tensor([ 2.8060e-02,  8.4451e-02,  2.7857e-02,  6.0436e-02,  1.0240e-01,\n",
      "         1.0442e-01,  1.0777e-01,  5.2331e-02, -9.7579e-02, -5.8547e-02,\n",
      "         1.0917e-01, -1.1880e-01,  1.6287e-01,  2.8477e-02,  1.1267e-01,\n",
      "        -1.3254e-02, -1.3777e-02, -5.9737e-02, -9.6358e-02, -9.6348e-04,\n",
      "        -2.3198e-02, -1.0766e-01,  2.5293e-02,  1.1446e-01, -5.8994e-02,\n",
      "         1.0858e-01, -5.3697e-02,  2.1325e-02, -2.7722e-03, -8.6258e-03,\n",
      "         5.9083e-02, -7.9570e-02,  6.7385e-02,  1.0690e-02,  1.2426e-01,\n",
      "        -3.2203e-02,  1.6404e-02, -1.0862e-01,  2.0717e-02, -3.1155e-02,\n",
      "        -1.6974e-03,  1.1224e-01, -1.0988e-02,  6.9968e-03, -1.5185e-01,\n",
      "        -4.4740e-02, -6.6722e-02, -2.5375e-02, -2.6176e-02,  1.8923e-02,\n",
      "         8.8948e-02, -3.6003e-02,  1.9198e-03, -4.4311e-03,  1.4737e-01,\n",
      "         9.2313e-02,  4.8728e-02, -9.2482e-02,  5.5996e-02,  2.2475e-02,\n",
      "        -2.6037e-02, -1.2994e-01,  9.9665e-02,  9.8336e-03, -1.3871e-02,\n",
      "        -1.3278e-01, -1.9746e-02, -3.1011e-02,  4.9562e-02,  1.5279e-01,\n",
      "         7.4409e-02, -5.0996e-02,  9.9460e-02,  1.0660e-01,  7.2300e-02,\n",
      "         8.3621e-02, -2.7988e-02,  5.8454e-02, -5.5878e-02,  1.8442e-01,\n",
      "         4.6471e-02,  2.9854e-02, -7.4765e-03,  1.3857e-01, -1.4116e-02,\n",
      "        -9.0064e-02,  7.6273e-02,  1.1544e-01, -7.6781e-02, -2.3600e-02,\n",
      "         1.0732e-02,  6.1821e-02, -6.3591e-02,  1.0263e-01,  1.1348e-01,\n",
      "         4.8190e-02, -5.9079e-03,  2.1432e-01, -4.4107e-04, -2.3640e-02,\n",
      "         9.7294e-02, -3.9043e-02, -1.2383e-01, -5.3639e-03,  1.2322e-02,\n",
      "         9.6903e-02,  3.1470e-02,  5.2484e-02, -8.2714e-03, -9.5551e-02,\n",
      "         6.8958e-02,  6.4113e-02, -2.5481e-02, -8.6435e-02, -4.3228e-02,\n",
      "         3.9220e-02,  4.9326e-02,  1.4816e-01,  8.3965e-02,  1.1136e-02,\n",
      "        -4.9719e-02,  9.8313e-02,  4.6175e-02, -8.2693e-02, -4.6066e-04,\n",
      "         1.7214e-02,  1.3973e-01,  5.8161e-02, -5.4858e-02, -3.8112e-02,\n",
      "        -8.6236e-02, -6.9095e-02,  6.9537e-02, -7.6838e-02, -4.4464e-02,\n",
      "         7.8224e-02,  1.6364e-01, -3.1058e-02, -6.7133e-02,  8.0285e-02,\n",
      "        -7.8057e-02, -5.4823e-02, -2.7009e-02, -1.0898e-02,  4.9419e-02,\n",
      "         1.3969e-01,  7.0205e-02,  2.8182e-02, -5.2513e-02, -6.5323e-02,\n",
      "         1.1037e-01,  9.7823e-02,  1.2985e-01,  3.4940e-02, -2.5365e-03,\n",
      "         5.5302e-02,  5.0309e-02,  1.4170e-01,  5.6564e-03,  1.0817e-01,\n",
      "         7.6410e-02, -2.8909e-02,  6.8625e-02,  1.9740e-01, -5.5000e-02,\n",
      "         9.1635e-03,  1.0423e-01,  7.8910e-02,  8.9812e-02, -9.4223e-03,\n",
      "         2.2311e-02, -4.3658e-02,  2.7254e-02,  1.0338e-01, -1.3441e-01,\n",
      "         6.3506e-02, -5.4626e-02, -1.3471e-02, -6.3990e-02,  8.1106e-02,\n",
      "         1.9641e-02, -1.8743e-01, -8.8395e-02,  1.1150e-01,  1.2400e-01,\n",
      "        -4.6730e-02,  1.1744e-02,  8.0286e-02,  5.3133e-02, -5.3440e-02,\n",
      "         8.2859e-02,  1.2274e-03, -3.5857e-02,  7.7174e-02, -9.3985e-02,\n",
      "        -1.4050e-01,  1.2583e-01, -1.1390e-02, -5.6548e-02,  7.6505e-03,\n",
      "         1.1531e-01,  6.5748e-02,  1.5536e-02, -1.4361e-02, -1.5699e-02,\n",
      "         4.4730e-02,  5.9830e-02,  1.1720e-01, -3.3184e-03, -8.4334e-02,\n",
      "        -5.9545e-02,  2.9199e-02,  5.8708e-02,  1.8560e-02, -5.2792e-02,\n",
      "         5.3461e-02,  9.3748e-02,  4.4521e-02, -5.6292e-02, -5.8625e-02,\n",
      "        -1.9803e-02, -1.7831e-02, -1.4222e-03,  1.8828e-01,  1.8515e-02,\n",
      "        -6.7523e-03,  1.1740e-01,  2.4853e-02,  6.9250e-03,  6.8234e-02,\n",
      "         7.7829e-02,  3.0850e-02,  1.2518e-01, -1.2185e-01,  9.0059e-02,\n",
      "        -4.3999e-02, -8.9968e-02,  5.6116e-02, -8.7673e-02, -1.1469e-02,\n",
      "        -5.4624e-02,  1.5443e-02,  8.1460e-02,  1.1209e-01,  7.5839e-02,\n",
      "        -7.7224e-02, -1.0241e-01, -6.2089e-03, -1.3174e-01, -1.0518e-02,\n",
      "         8.3043e-02,  8.7483e-02,  2.9098e-02,  4.6744e-02,  5.2103e-02,\n",
      "        -3.2323e-02,  2.5569e-02,  7.2226e-02,  8.8333e-02,  3.3362e-02,\n",
      "         1.1843e-01,  3.3497e-02,  1.7166e-01,  1.7681e-01,  2.0851e-01,\n",
      "         1.2829e-01,  1.9171e-01,  6.7933e-02,  1.8254e-02,  1.5829e-01,\n",
      "        -9.2132e-03,  1.0270e-01,  1.7650e-02,  1.5469e-01,  2.5334e-01,\n",
      "         8.5249e-02,  1.3280e-01, -5.2993e-03,  7.0177e-02,  1.7001e-01,\n",
      "         4.0841e-02,  9.9114e-02,  4.6663e-02,  8.1968e-02,  3.0951e-02,\n",
      "         1.1149e-01,  1.5740e-01,  1.0194e-01, -1.3551e-02,  4.3293e-02,\n",
      "         8.9806e-02,  9.3330e-02,  5.2221e-02,  8.9575e-02,  4.6950e-02,\n",
      "         1.3211e-01,  9.9231e-03, -1.6100e-02,  2.9265e-02, -1.4451e-02,\n",
      "         2.2697e-02,  1.1592e-01,  6.0648e-02,  1.3367e-01,  1.1667e-01,\n",
      "        -5.2681e-02,  5.4411e-02,  1.1136e-01,  1.0282e-02,  4.7602e-02,\n",
      "         6.2181e-03,  2.1568e-01,  4.5508e-03,  9.3013e-02,  1.0172e-01,\n",
      "         6.4110e-02,  2.0140e-01,  1.2883e-01, -7.5227e-02,  1.5106e-01,\n",
      "         1.8506e-01,  1.6872e-01,  1.6121e-01,  7.0322e-02,  7.3884e-02,\n",
      "         1.1027e-01,  1.9465e-01,  8.6349e-02,  2.9496e-03,  1.4785e-01,\n",
      "         9.5064e-02, -2.2370e-03,  1.4360e-01,  1.0077e-01, -1.0420e-02,\n",
      "         1.1594e-01,  1.2571e-01,  1.7041e-01,  1.8156e-01,  1.2437e-01,\n",
      "         1.4397e-01,  1.0095e-01,  4.3630e-02,  2.0102e-01,  1.2886e-01,\n",
      "        -3.4381e-02,  6.8502e-02,  1.3076e-01,  1.8045e-01,  4.2953e-02,\n",
      "         4.6614e-03,  5.7292e-02,  6.2846e-02,  1.0498e-01,  7.6033e-02,\n",
      "         2.8251e-02,  2.2736e-01,  4.8544e-02,  8.8239e-02,  7.0537e-02,\n",
      "         4.9193e-02, -5.3753e-03,  2.4005e-01,  1.7574e-01,  2.0601e-01,\n",
      "         9.9362e-02, -6.1774e-02,  4.1620e-02,  1.0981e-01,  5.4771e-02,\n",
      "         1.7864e-01,  9.0780e-02,  6.8074e-02,  9.2746e-02,  2.0279e-02,\n",
      "         1.0255e-01,  7.4113e-02,  7.2660e-03,  7.6075e-02,  1.3638e-01,\n",
      "         5.8275e-02,  4.7696e-02,  1.7077e-01,  6.6990e-02,  2.7094e-03,\n",
      "         7.0830e-02,  1.9119e-01,  3.2141e-02,  1.8548e-01,  1.6717e-01,\n",
      "         1.0619e-01,  1.5607e-01,  2.0942e-01,  9.7593e-02,  1.0150e-01,\n",
      "         5.4376e-02,  1.0191e-01,  8.0596e-02,  9.4976e-02, -5.7972e-03,\n",
      "         9.7893e-02,  1.1296e-01, -1.4789e-02,  8.4757e-02, -1.8934e-02,\n",
      "         1.0912e-01,  1.6746e-01,  1.2906e-01,  1.6058e-01,  7.2655e-02,\n",
      "         1.2641e-01, -9.6045e-03,  9.2586e-02,  1.6524e-01,  8.6515e-02,\n",
      "         1.6531e-01,  1.4648e-01,  1.3292e-01,  5.3019e-03,  2.0734e-02,\n",
      "        -6.2368e-04,  1.2193e-01,  2.0359e-01,  8.9507e-02,  7.6228e-02,\n",
      "         1.7408e-01,  3.0622e-02,  4.9772e-02, -3.3467e-02,  1.3870e-01,\n",
      "         1.3987e-01,  2.0380e-01,  1.1184e-01,  3.5179e-02,  1.1344e-01,\n",
      "         1.8786e-01,  5.7131e-02,  1.5105e-01,  3.4585e-02,  2.2689e-01,\n",
      "         1.0205e-01,  2.2209e-02,  2.2705e-01,  1.4179e-01,  1.2543e-01,\n",
      "        -1.8226e-02,  1.8420e-01,  1.5167e-01, -5.9125e-02,  1.8569e-01,\n",
      "         1.2383e-01,  1.1369e-01,  7.2192e-02,  9.8837e-02,  9.5695e-02,\n",
      "         1.4707e-01, -7.6736e-03,  1.1468e-01,  2.0104e-01, -1.7344e-02,\n",
      "         1.2915e-01,  5.2989e-02,  1.7775e-01, -2.5848e-03,  1.2320e-01,\n",
      "         1.3371e-01,  7.0810e-02,  7.6128e-02,  1.3242e-01,  1.8661e-02,\n",
      "        -1.8082e-02,  7.2632e-02,  8.5219e-02,  1.0463e-01,  1.0888e-01,\n",
      "         2.9540e-01,  1.4300e-01,  8.4113e-02,  8.5045e-02,  1.2096e-01,\n",
      "         2.2162e-01,  8.2018e-02,  1.5192e-01,  1.6069e-01,  1.6436e-01,\n",
      "         4.8366e-02,  1.3038e-01,  1.2546e-01,  1.6214e-02,  1.3710e-01,\n",
      "        -5.7996e-02,  3.6842e-02,  1.6577e-01,  1.1962e-01,  4.1997e-02,\n",
      "         2.4707e-01,  8.7374e-02,  8.1079e-02,  1.9846e-01,  8.7825e-02,\n",
      "         1.8847e-01,  2.2053e-01,  9.4800e-02,  3.7125e-03,  2.3230e-01,\n",
      "         1.1525e-01,  4.9151e-02, -7.6483e-02,  1.0587e-01,  1.2332e-01,\n",
      "        -2.5625e-02,  1.5906e-01,  3.2430e-02, -5.3773e-02, -6.5301e-02,\n",
      "        -1.1851e-01,  9.5990e-02, -8.2045e-02, -4.3697e-02,  9.9031e-03,\n",
      "         7.5845e-02,  4.9984e-02,  1.2851e-01,  5.1131e-02,  5.4528e-02,\n",
      "        -8.7201e-02, -1.6470e-01, -3.4757e-02,  1.3370e-01, -1.8790e-02,\n",
      "         7.7283e-02,  6.3305e-03, -8.0773e-02,  7.8983e-02,  2.3512e-02,\n",
      "        -1.0768e-01,  4.3562e-02,  6.0183e-03, -1.0089e-01, -4.5247e-03,\n",
      "        -5.8843e-02, -3.6449e-03,  3.3682e-02, -3.0768e-03,  3.9715e-03,\n",
      "        -9.2105e-02,  9.6225e-02,  7.7747e-02, -9.6261e-02,  8.0777e-02,\n",
      "         4.4593e-02,  3.6418e-02, -2.6137e-02, -1.0826e-01, -2.9529e-02,\n",
      "         2.1872e-02, -6.7154e-02,  9.7587e-02, -6.6838e-03,  1.7004e-02,\n",
      "         1.2124e-01,  7.7792e-02, -1.8297e-01,  2.4068e-04,  6.2903e-02,\n",
      "         1.4084e-02, -1.4085e-01, -4.5579e-02, -3.6292e-02,  6.1190e-02,\n",
      "         6.8757e-02, -1.3402e-01,  4.9093e-02,  1.1536e-01,  1.4144e-01,\n",
      "         5.7430e-03, -6.1334e-02,  4.4257e-02,  7.8455e-02,  1.8137e-02,\n",
      "        -8.2695e-02,  6.6843e-02,  4.0160e-02,  3.8323e-02, -4.8667e-02,\n",
      "         3.6890e-02, -9.7230e-02,  4.2601e-02, -1.0269e-01,  5.2150e-02,\n",
      "         7.1805e-02,  1.4683e-01,  4.6147e-02,  2.7333e-02,  3.5626e-02,\n",
      "        -3.5115e-02, -1.2890e-01, -3.9302e-02, -4.4806e-03, -3.7939e-02,\n",
      "        -1.3763e-01, -1.0795e-01, -1.4654e-01, -5.3341e-02,  4.8093e-02,\n",
      "        -6.5561e-02, -6.9400e-02,  1.7563e-01, -1.7896e-01, -4.4177e-02,\n",
      "        -1.5337e-01, -6.5759e-02,  6.2891e-02,  7.7866e-02, -8.6959e-02,\n",
      "        -4.1590e-03,  7.3329e-02,  1.4098e-01, -5.1701e-02,  1.0347e-01,\n",
      "        -5.9140e-02, -2.2054e-03, -7.5328e-02,  8.2302e-02,  8.3880e-03,\n",
      "        -4.4415e-02,  1.1169e-01, -7.0748e-02, -7.2113e-02, -1.2861e-01,\n",
      "         9.2392e-02, -8.5995e-02,  9.1615e-02,  7.1542e-02,  1.8520e-01,\n",
      "         4.9100e-02, -6.5529e-02,  3.1215e-02, -8.0097e-03, -1.0244e-01,\n",
      "         7.2212e-02,  9.6296e-02, -6.3707e-02,  1.2327e-01, -1.0452e-01,\n",
      "         4.7078e-02,  7.1582e-02, -3.1309e-02, -1.1135e-01,  3.7525e-02,\n",
      "         4.9988e-02, -8.0929e-02,  2.1220e-02,  9.5361e-02,  3.3602e-02,\n",
      "         3.3306e-02,  9.4272e-02, -3.8412e-02, -1.6617e-01, -3.7186e-02,\n",
      "         5.2881e-02,  4.7257e-03,  6.8487e-02, -7.9160e-02,  7.1605e-02,\n",
      "         7.2086e-04, -4.7466e-02,  4.4886e-02,  3.6379e-02, -2.5762e-02,\n",
      "         2.1913e-02,  1.9236e-02,  3.1982e-02,  6.2491e-02, -4.3769e-02,\n",
      "         3.6722e-02,  7.7092e-02, -6.7725e-03, -2.6549e-01, -6.0571e-02,\n",
      "         6.3754e-02,  5.4656e-02,  6.9256e-02,  6.9776e-02,  1.2449e-01,\n",
      "        -3.5115e-02, -3.7334e-02, -4.9502e-02,  2.3773e-02,  8.9336e-02,\n",
      "        -7.1802e-02,  7.7190e-02, -8.6449e-02,  1.2482e-01,  1.0488e-01,\n",
      "        -1.6444e-02, -4.2577e-02, -2.9244e-02, -2.2274e-02,  7.8841e-02,\n",
      "        -4.0859e-02, -8.4202e-02, -3.3328e-02, -7.6918e-03, -2.9979e-02,\n",
      "        -6.2875e-02, -1.4208e-01, -6.1910e-02,  6.7923e-03, -5.5177e-02,\n",
      "         2.2302e-02,  7.0417e-02,  8.8274e-02, -5.4226e-02, -2.1462e-02,\n",
      "        -6.5973e-03, -8.5797e-02,  4.5437e-02,  8.0422e-02, -1.2000e-03,\n",
      "         7.6649e-02, -3.4282e-02,  5.6316e-02, -6.6680e-02, -3.1534e-03,\n",
      "         4.0909e-02, -1.0463e-01, -6.3476e-02,  8.4211e-04, -6.7110e-04,\n",
      "        -7.3256e-02, -7.3660e-02,  4.3145e-02,  1.9206e-01,  6.2203e-02,\n",
      "         7.3864e-02,  8.3419e-02, -3.5472e-02, -9.1567e-02,  1.9426e-02,\n",
      "        -1.3129e-02, -1.1135e-01,  3.4945e-03, -6.6802e-02, -1.4134e-01,\n",
      "        -4.3917e-02, -9.9916e-02, -5.3978e-02,  8.9570e-02,  5.0390e-02,\n",
      "        -7.1331e-02,  4.5459e-02, -7.5699e-02,  3.0687e-02, -3.4857e-02,\n",
      "        -6.6457e-02, -5.5104e-02,  3.0560e-02,  1.1591e-01, -8.7122e-02,\n",
      "        -3.3881e-02, -2.0864e-02, -3.7612e-02,  9.7796e-03,  2.4769e-02,\n",
      "         3.9927e-03, -8.0057e-03,  1.1552e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "encoder.rnn.bias_hh_l0 Parameter containing:\n",
      "tensor([ 7.7630e-02,  1.2374e-01,  1.8307e-02,  9.8431e-02,  8.3534e-02,\n",
      "         3.0774e-02,  1.1430e-01,  5.4689e-02, -2.8150e-02,  1.2123e-02,\n",
      "         1.8340e-01, -1.3904e-01,  1.5738e-01,  5.1647e-02,  5.1516e-02,\n",
      "         1.7673e-02, -3.9614e-02, -7.5544e-02, -3.1972e-02, -2.6672e-02,\n",
      "         6.4111e-02, -5.6087e-02,  7.7746e-02,  1.5342e-01, -6.9556e-02,\n",
      "         3.2556e-02, -1.9423e-02, -8.2572e-02, -7.3412e-02, -2.6122e-03,\n",
      "         5.6366e-02, -4.0335e-02,  3.5508e-02,  4.4691e-02,  1.1382e-01,\n",
      "        -3.1049e-02, -4.0138e-03, -1.0958e-01,  2.6633e-02, -5.5175e-02,\n",
      "        -7.1877e-02,  8.3402e-02, -2.6368e-02,  7.5613e-02, -1.2811e-01,\n",
      "        -1.2990e-01,  1.9878e-02, -1.8320e-03, -6.5067e-02,  6.5082e-02,\n",
      "         7.2879e-02, -3.9275e-02, -4.5568e-03, -1.0052e-01,  1.7334e-01,\n",
      "         3.3738e-02,  7.7443e-02, -1.1029e-01,  8.6883e-02,  2.9974e-02,\n",
      "        -1.3700e-02, -1.2466e-01,  1.1259e-01, -4.3419e-02,  4.2467e-03,\n",
      "        -1.2509e-01, -6.5343e-02,  1.3649e-02,  5.5244e-02,  1.4535e-01,\n",
      "         1.7432e-02, -1.9771e-02,  5.3443e-02,  6.6227e-03,  1.3637e-01,\n",
      "         4.2225e-02,  2.3765e-02,  1.6122e-01, -1.3947e-02,  1.7115e-01,\n",
      "         7.2598e-02,  1.0445e-01, -2.1440e-02,  9.5866e-02, -8.0432e-02,\n",
      "        -1.0669e-01,  7.3520e-02,  7.2270e-02,  1.2524e-03, -1.2331e-02,\n",
      "        -4.2210e-02,  1.3850e-01, -1.0341e-01,  6.9163e-02,  2.0206e-02,\n",
      "         6.9700e-02, -6.9169e-02,  1.0152e-01, -6.3524e-02, -4.0368e-02,\n",
      "         9.0532e-02, -2.0111e-02, -9.0483e-02, -7.0296e-02,  5.0879e-02,\n",
      "         5.3037e-02,  9.9906e-02,  7.3571e-02, -7.7402e-02, -4.8226e-02,\n",
      "         1.2771e-02,  9.1017e-02,  5.1377e-02, -5.1839e-02, -6.0604e-02,\n",
      "         3.6985e-02,  7.5399e-02,  1.3312e-01,  1.1260e-01,  3.4805e-02,\n",
      "         4.9197e-02,  9.1248e-02,  1.0117e-01, -7.3688e-02, -9.2684e-03,\n",
      "         4.9950e-02,  8.8936e-02,  8.7769e-02, -5.5526e-02, -6.7455e-02,\n",
      "        -1.6854e-02, -1.0692e-01,  5.9855e-02, -7.1898e-02,  3.7651e-02,\n",
      "         8.5618e-02,  1.4692e-01, -1.3288e-01, -2.5120e-03,  1.5378e-02,\n",
      "        -1.4382e-01, -2.4249e-02, -1.9292e-02, -6.0309e-02,  4.8865e-02,\n",
      "         1.0117e-01,  1.5666e-01,  3.7114e-02, -2.8268e-03, -6.6070e-02,\n",
      "         1.0217e-01,  1.3802e-01,  7.0659e-02,  1.0873e-01, -6.6772e-02,\n",
      "         4.8434e-03,  1.1915e-02,  4.1655e-02,  9.5494e-03,  5.4349e-02,\n",
      "         5.0365e-02, -3.4279e-02,  6.2520e-02,  2.0033e-01, -1.1138e-01,\n",
      "         7.6080e-02,  1.5325e-01,  7.3386e-02,  7.1854e-02, -8.4584e-02,\n",
      "         3.5248e-02, -4.9029e-02,  9.5559e-02,  1.2149e-01, -5.9803e-02,\n",
      "         6.9538e-02, -8.6902e-02,  3.8984e-02, -3.8140e-02,  7.2706e-02,\n",
      "        -1.5162e-02, -1.3628e-01, -1.2000e-01,  1.0131e-01,  1.1421e-01,\n",
      "        -9.6129e-02,  1.1817e-01,  2.3867e-02,  2.9149e-02, -7.7708e-03,\n",
      "         1.0261e-01,  8.9311e-02, -6.0125e-02,  1.6437e-02, -1.0349e-01,\n",
      "        -1.0401e-01,  2.4898e-02, -9.6330e-02, -3.8338e-02, -6.2640e-03,\n",
      "         6.6064e-02,  3.8384e-02,  3.1635e-02,  2.1210e-02, -1.0336e-04,\n",
      "         2.3089e-02,  1.0579e-01,  1.5649e-01,  2.9924e-02, -1.1372e-01,\n",
      "         1.8897e-02,  2.1917e-02,  2.4930e-02,  4.4113e-03, -6.4368e-02,\n",
      "         9.2511e-02,  4.9430e-02,  3.0186e-02, -9.2210e-02, -1.8558e-02,\n",
      "         2.5555e-02,  2.0373e-03, -6.4265e-02,  1.8793e-01,  1.7643e-02,\n",
      "        -6.9326e-02,  4.8557e-02,  2.9622e-02,  6.0881e-03,  7.1217e-02,\n",
      "         7.8669e-02,  3.9250e-02,  1.1749e-01, -8.4926e-02,  8.9357e-02,\n",
      "        -7.5465e-02, -1.5556e-01,  6.5761e-02, -3.3559e-02, -2.4452e-02,\n",
      "         2.2636e-02,  1.5885e-02,  7.4646e-02,  1.4663e-01,  2.3482e-02,\n",
      "        -5.7424e-03, -1.3372e-01, -9.5419e-03, -1.5068e-01,  9.8613e-03,\n",
      "         4.1668e-02,  6.6216e-02, -1.7852e-02,  1.2653e-01, -7.3820e-03,\n",
      "        -2.0418e-02,  1.0531e-01, -3.4955e-02,  4.8967e-02,  1.1928e-01,\n",
      "         1.4336e-01,  9.4690e-03,  1.8263e-01,  2.0961e-01,  1.6730e-01,\n",
      "         9.6837e-02,  1.3733e-01,  1.7117e-02,  5.1336e-02,  9.3962e-02,\n",
      "        -2.4982e-02,  2.4186e-02,  7.6396e-02,  6.9454e-02,  1.7203e-01,\n",
      "         8.5945e-02,  1.4986e-01, -6.0202e-03,  6.2358e-02,  1.5027e-01,\n",
      "         4.1769e-02,  1.3206e-01,  5.0265e-02,  1.6568e-01,  8.4515e-02,\n",
      "         1.2964e-01,  1.4100e-01,  1.0268e-01,  1.1415e-02, -1.6740e-02,\n",
      "         1.5994e-01,  1.0011e-01,  4.7909e-02,  6.9636e-02,  3.0538e-02,\n",
      "         8.6874e-02,  7.0625e-02, -8.0612e-03,  1.3375e-02, -3.2009e-02,\n",
      "         1.2107e-01,  1.7343e-01,  2.2310e-02,  1.9100e-01,  1.3129e-01,\n",
      "        -2.3329e-02,  9.3921e-04,  1.1256e-01, -6.2309e-02,  1.0140e-01,\n",
      "         1.0113e-01,  2.2007e-01,  2.2708e-02,  1.2267e-01,  1.2047e-01,\n",
      "         9.8430e-02,  1.3277e-01,  1.1013e-01, -1.3265e-01,  1.2874e-01,\n",
      "         8.2797e-02,  1.3958e-01,  1.9204e-01,  4.5976e-02,  1.6192e-01,\n",
      "         1.0910e-01,  1.2116e-01,  5.1606e-02, -6.9081e-03,  1.0964e-01,\n",
      "         1.2427e-01,  1.0831e-01,  1.6637e-01,  1.1718e-01,  8.7958e-02,\n",
      "         1.6288e-01,  1.0090e-01,  1.4208e-01,  1.5690e-01,  1.3163e-01,\n",
      "         1.7729e-01,  1.6918e-01,  9.0432e-02,  2.0311e-01,  7.6290e-02,\n",
      "        -7.9261e-02, -2.8317e-02,  4.7767e-02,  1.2623e-01,  2.5965e-02,\n",
      "        -4.5917e-02,  1.4628e-01,  3.9224e-02,  2.4644e-02,  1.4538e-01,\n",
      "         7.2994e-02,  1.6373e-01, -8.8301e-03,  6.9090e-02,  7.2518e-02,\n",
      "         7.8704e-02,  6.1517e-04,  1.7267e-01,  1.1535e-01,  1.3640e-01,\n",
      "         7.1151e-02, -5.3438e-03,  6.0777e-02,  4.9549e-02,  8.8749e-03,\n",
      "         1.7678e-01,  6.2447e-02,  8.6349e-02,  1.2457e-01,  4.4340e-03,\n",
      "         1.5839e-02,  1.2216e-01, -8.3632e-02,  9.4716e-02,  1.7005e-01,\n",
      "        -1.6433e-02,  8.8571e-02,  1.4064e-01, -1.8333e-03, -4.8441e-03,\n",
      "         1.7232e-02,  2.0644e-01,  5.3586e-02,  2.2830e-01,  1.5509e-01,\n",
      "         1.2166e-01,  1.9458e-01,  1.5692e-01,  1.0802e-01,  1.3652e-01,\n",
      "         4.2272e-02,  7.1540e-02,  5.7277e-02,  1.1868e-01,  6.2303e-02,\n",
      "         5.7657e-02,  1.5487e-01,  3.2017e-02,  1.0028e-01,  7.2095e-02,\n",
      "         1.8151e-01,  1.0948e-01,  4.1822e-02,  1.6569e-01,  1.6567e-01,\n",
      "         4.8895e-02, -6.9492e-02,  1.4393e-01,  2.2540e-01,  8.8828e-02,\n",
      "         2.1609e-01,  1.3296e-01,  9.0168e-02,  4.5162e-02,  3.2889e-02,\n",
      "        -5.2151e-02,  1.4683e-01,  1.5494e-01,  4.8052e-02,  3.5679e-02,\n",
      "         8.2598e-02, -6.6734e-02,  2.2075e-02, -4.6968e-02,  1.9326e-01,\n",
      "         1.7461e-01,  8.7071e-02,  6.7151e-02,  9.7336e-02,  8.0370e-02,\n",
      "         2.3398e-01,  5.4829e-02,  7.8247e-02,  1.1609e-01,  1.4089e-01,\n",
      "         1.5086e-01,  6.2964e-02,  1.9468e-01,  1.2608e-01,  1.0957e-01,\n",
      "         1.0399e-02,  1.8767e-01,  8.3136e-02,  4.2610e-02,  2.1370e-01,\n",
      "         6.3049e-02,  7.5547e-03,  1.5636e-01,  7.2492e-02,  1.8269e-03,\n",
      "         1.3631e-01,  4.9881e-02,  1.3329e-01,  1.7509e-01, -1.1810e-01,\n",
      "         6.4944e-02,  1.5287e-01,  1.6351e-01,  8.7245e-02,  4.2496e-02,\n",
      "         1.1196e-01,  7.1535e-02,  5.3000e-02,  2.2090e-01,  8.2155e-02,\n",
      "        -1.5695e-02,  8.8717e-02,  7.0676e-02,  4.3878e-02,  7.9051e-02,\n",
      "         2.4087e-01,  1.5883e-01,  5.5856e-02,  1.4599e-01,  1.0699e-01,\n",
      "         2.1074e-01,  3.3584e-02,  5.8228e-02,  1.1292e-01,  1.5316e-01,\n",
      "         1.8320e-02,  1.2482e-01,  9.9405e-02,  3.3551e-02,  1.5629e-01,\n",
      "         1.5832e-02,  4.2524e-02,  1.2508e-01,  7.9744e-02,  3.2440e-02,\n",
      "         2.2058e-01,  9.1516e-02,  1.2854e-02,  2.0866e-01,  5.2466e-02,\n",
      "         1.2220e-01,  1.9945e-01,  1.0238e-01, -1.3391e-02,  1.5097e-01,\n",
      "         7.6123e-02,  2.5621e-02, -1.5646e-02,  1.3173e-01,  1.3745e-01,\n",
      "         4.2093e-02,  1.4930e-01,  8.6549e-02,  5.1439e-02, -3.9830e-02,\n",
      "        -1.3410e-02,  5.9778e-03,  2.4076e-02, -7.2008e-02, -9.5770e-02,\n",
      "         1.0998e-02,  9.7319e-02,  7.7445e-02, -4.9660e-02,  1.4356e-02,\n",
      "        -1.0981e-01, -1.6606e-01,  8.5591e-02,  1.9736e-02,  3.5984e-02,\n",
      "         3.7711e-02, -3.7576e-03, -7.6817e-02,  1.9921e-02,  7.0248e-02,\n",
      "        -8.2429e-02,  2.1523e-02,  2.0300e-02, -9.7940e-02,  3.4773e-02,\n",
      "         6.3856e-02,  8.4166e-02,  5.5154e-02, -4.5671e-02, -1.1034e-01,\n",
      "        -1.3657e-01,  1.5761e-01,  4.1344e-02, -2.8844e-02,  3.2292e-02,\n",
      "         1.1752e-01,  4.0204e-03, -2.6350e-03, -9.3187e-02, -5.9879e-02,\n",
      "        -8.1751e-02, -7.0105e-03, -7.7915e-03, -4.3803e-02,  6.4089e-04,\n",
      "         4.9841e-02,  5.2242e-02, -1.2784e-01,  2.0981e-02,  1.0144e-01,\n",
      "        -2.1765e-02, -5.5472e-02,  9.4233e-02, -9.5529e-02,  4.2431e-02,\n",
      "         3.6163e-02, -7.2002e-02, -5.7338e-02, -3.4863e-02,  1.0221e-01,\n",
      "         8.5979e-02,  2.3248e-02,  6.2514e-02, -6.9466e-02, -3.0201e-03,\n",
      "        -6.8887e-02,  2.4222e-02, -1.7944e-02,  5.3301e-02, -1.5685e-01,\n",
      "        -2.0420e-02, -7.9769e-03,  3.1174e-02, -8.7840e-02,  2.0547e-02,\n",
      "         1.9350e-02,  3.4631e-02,  3.9527e-02,  6.3371e-02, -9.3065e-02,\n",
      "        -7.6598e-02, -1.3824e-01, -1.3185e-02, -1.0910e-01, -1.3010e-02,\n",
      "        -5.3560e-02, -8.9722e-02,  2.8655e-02,  2.6004e-02,  2.4400e-02,\n",
      "        -6.6884e-02, -7.6542e-02,  9.4907e-02,  1.1042e-02, -4.6389e-03,\n",
      "        -6.4255e-02,  6.8973e-02,  1.0664e-01,  1.0467e-01, -4.9078e-02,\n",
      "        -7.4135e-02,  1.5748e-03,  1.1140e-01, -9.1281e-02,  1.7192e-02,\n",
      "        -3.0302e-02, -6.8679e-02, -7.1113e-02,  5.0102e-02,  7.6640e-02,\n",
      "         5.8265e-02, -1.6490e-02, -1.8309e-02, -4.2415e-02, -1.2178e-01,\n",
      "         1.0894e-01, -5.6268e-02,  6.1496e-02,  3.7749e-02,  5.4660e-02,\n",
      "         1.7797e-02, -8.1865e-02,  4.9766e-02,  2.6621e-02, -7.5018e-02,\n",
      "         8.6086e-02,  3.5582e-02, -6.8776e-02, -2.7460e-02,  9.7388e-03,\n",
      "        -2.6156e-02,  3.6053e-02,  7.8129e-02, -5.6740e-02, -7.1581e-02,\n",
      "         1.3667e-02, -2.5527e-02, -6.7854e-02,  4.5513e-03,  5.5508e-02,\n",
      "         1.6435e-02,  4.0549e-02,  1.8444e-02, -1.7472e-01, -5.1805e-02,\n",
      "        -1.6532e-02, -5.5089e-02,  4.6051e-02, -3.9318e-02,  3.2966e-02,\n",
      "         1.3517e-03, -2.8381e-02,  9.9791e-02,  1.0403e-01,  3.8483e-02,\n",
      "        -3.4339e-02,  3.8997e-02, -4.9354e-02, -4.5491e-02,  1.5518e-02,\n",
      "         2.0892e-03, -1.4159e-01, -3.9312e-02, -1.4334e-01, -1.0641e-01,\n",
      "         1.1134e-02,  1.9342e-02,  3.5291e-02,  7.5574e-02,  5.3961e-02,\n",
      "        -6.9907e-02, -2.7179e-02,  1.5667e-02,  5.1053e-03, -8.8809e-02,\n",
      "         4.4712e-02, -2.6763e-02, -2.5603e-02,  4.5142e-02, -9.0913e-03,\n",
      "         2.3059e-02, -4.8738e-02,  1.3786e-02, -4.5527e-02,  9.4121e-02,\n",
      "        -6.6777e-02, -1.1643e-01,  5.6766e-02,  5.0304e-03, -9.6676e-02,\n",
      "         6.5581e-02, -2.4925e-02,  7.8360e-02,  7.7799e-02, -1.0481e-01,\n",
      "         3.1628e-02,  4.3935e-02,  7.2814e-02,  1.1472e-02,  3.3445e-02,\n",
      "         1.1511e-01,  3.2962e-02,  6.8145e-02, -1.3302e-02, -1.0207e-01,\n",
      "         1.6386e-02, -4.4955e-02,  3.6668e-02, -1.0057e-03,  5.4021e-03,\n",
      "         9.4049e-02, -6.0984e-02,  2.3101e-02, -5.4905e-02, -5.1370e-02,\n",
      "        -8.2705e-02, -6.6761e-02, -3.0711e-02,  1.3690e-01,  1.0523e-01,\n",
      "        -4.1450e-02,  6.2686e-02, -5.9634e-03, -9.4582e-02, -7.7997e-02,\n",
      "         4.6328e-02, -1.0986e-01,  7.1228e-02, -8.1814e-02, -1.4662e-01,\n",
      "        -9.6606e-03, -7.3292e-02, -4.4427e-02, -5.4742e-02,  6.5125e-03,\n",
      "        -3.4666e-02,  7.0984e-02, -6.4111e-02,  8.1381e-02, -5.1647e-02,\n",
      "         4.5178e-02,  6.6085e-02, -3.3897e-02,  4.4186e-02, -6.0329e-02,\n",
      "         3.3339e-02, -4.3727e-02,  7.1383e-02, -7.4462e-02,  5.4800e-03,\n",
      "         8.4276e-02, -1.1966e-01, -2.7157e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "decoder.rnn.weight_ih_l0 Parameter containing:\n",
      "tensor([[ 0.0058, -0.2056,  0.0310,  ..., -0.0170,  0.1232, -0.1601],\n",
      "        [ 0.0060,  0.0659,  0.0300,  ..., -0.0633,  0.0152,  0.0275],\n",
      "        [-0.1330, -0.0243,  0.0359,  ..., -0.1199, -0.0412,  0.1341],\n",
      "        ...,\n",
      "        [ 0.0448, -0.0864,  0.0460,  ...,  0.0357,  0.0544, -0.1309],\n",
      "        [-0.0706,  0.0507, -0.2272,  ...,  0.0874,  0.0179, -0.0516],\n",
      "        [-0.0404, -0.1260,  0.0645,  ..., -0.1240, -0.0626,  0.0319]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "decoder.rnn.weight_hh_l0 Parameter containing:\n",
      "tensor([[ 0.2510, -0.1203,  0.0088,  ..., -0.0282, -0.0301, -0.1337],\n",
      "        [ 0.0279, -0.3556, -0.0088,  ..., -0.0428, -0.0027,  0.0282],\n",
      "        [-0.1459, -0.0329,  0.0538,  ...,  0.1028, -0.0430, -0.0798],\n",
      "        ...,\n",
      "        [-0.2180,  0.0393,  0.0045,  ...,  0.3249,  0.0267, -0.0018],\n",
      "        [ 0.0833,  0.0873, -0.0397,  ...,  0.0244,  1.1200, -0.0996],\n",
      "        [-0.0665, -0.2853, -0.0053,  ...,  0.0178,  0.0734,  1.1482]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "decoder.rnn.bias_ih_l0 Parameter containing:\n",
      "tensor([ 5.0203e-02,  6.0622e-02,  1.8788e-01,  9.6849e-02,  4.1389e-02,\n",
      "         9.4942e-02,  1.4515e-01,  1.2000e-01,  2.0533e-02,  1.9728e-01,\n",
      "         3.8756e-02, -5.5232e-02,  4.4797e-02,  2.1161e-01,  7.2365e-03,\n",
      "         2.2233e-01,  1.4918e-01,  2.0711e-01,  6.4814e-02,  1.1420e-01,\n",
      "         1.7882e-01,  2.2329e-01,  1.1747e-01,  8.3255e-02,  6.6990e-02,\n",
      "         5.5089e-02,  5.5867e-02,  4.2940e-02,  1.3906e-01,  1.5385e-01,\n",
      "         2.4661e-01,  8.0327e-02,  1.7011e-01,  1.1364e-01,  1.3158e-01,\n",
      "         8.2911e-02, -1.2022e-02,  9.8366e-02,  1.0755e-01,  2.1013e-01,\n",
      "         8.1395e-02,  1.0759e-01,  5.8539e-02,  1.3918e-01, -7.2511e-03,\n",
      "         2.0928e-01,  1.0104e-01,  2.2925e-01,  1.5364e-01,  2.1187e-01,\n",
      "         8.6811e-02,  1.1180e-01,  1.8314e-01,  7.5826e-02,  1.5343e-01,\n",
      "         1.1688e-01,  4.9178e-02,  2.0710e-01,  1.0981e-01,  6.1043e-02,\n",
      "         1.5681e-01,  1.3164e-01,  1.0467e-01,  4.1773e-02,  6.3968e-02,\n",
      "         2.1074e-01,  4.6162e-02,  1.4925e-01,  5.3004e-02,  1.7862e-01,\n",
      "         4.6362e-02,  1.3646e-01,  1.5535e-01,  3.7120e-02,  9.1668e-02,\n",
      "         8.0290e-02,  2.2151e-01,  1.2732e-01,  1.2240e-01,  1.7446e-01,\n",
      "         9.6436e-02,  5.5685e-02,  1.1881e-01,  3.7296e-02,  1.7407e-01,\n",
      "         9.0395e-02, -8.2157e-03, -1.6263e-02,  1.4581e-02,  1.1458e-01,\n",
      "         1.7814e-01,  1.2657e-01,  6.6391e-02,  8.0094e-02,  1.0246e-01,\n",
      "         1.2156e-01,  2.3074e-01,  1.9816e-01,  2.7147e-02,  1.9973e-01,\n",
      "         2.3182e-01, -6.1473e-03,  4.6161e-02,  1.1475e-01,  8.2622e-02,\n",
      "        -2.9108e-02,  3.3557e-02,  9.5471e-02,  2.4624e-01,  6.7992e-02,\n",
      "        -5.7318e-03,  1.7894e-01,  1.2031e-01,  2.7977e-01,  1.6037e-01,\n",
      "         3.8394e-02,  1.0370e-01,  1.2970e-01,  1.5261e-01,  1.2612e-01,\n",
      "         1.5264e-01,  1.7536e-01,  2.4580e-02,  1.2974e-01,  1.2612e-02,\n",
      "         2.5262e-02,  7.3671e-02,  1.7278e-01,  1.4288e-01,  1.5623e-01,\n",
      "         1.8360e-01,  1.8087e-01,  3.4159e-02,  9.3344e-02,  1.6862e-01,\n",
      "         3.1967e-02,  3.9666e-02,  9.6062e-02,  1.6906e-01,  1.6915e-01,\n",
      "         1.0531e-01,  2.1246e-01,  8.4767e-02,  5.5430e-02,  3.7795e-02,\n",
      "         1.5930e-01,  2.2175e-02,  3.5395e-02,  8.7426e-02,  2.0875e-01,\n",
      "         3.4301e-02,  3.4338e-02,  7.2436e-02,  6.7930e-02,  2.7128e-01,\n",
      "         4.8481e-02,  1.9727e-01,  2.3961e-01,  8.3147e-02,  1.7429e-01,\n",
      "         1.5927e-01,  5.5414e-03,  1.2872e-01,  4.4568e-02,  1.2282e-01,\n",
      "         1.2650e-01,  1.6908e-01,  1.0566e-01,  3.1137e-02,  2.2338e-01,\n",
      "         1.0112e-01,  1.5144e-01,  5.1061e-02, -7.3131e-03,  1.7319e-01,\n",
      "         6.6358e-02,  1.1483e-01,  8.4147e-02,  1.7520e-01,  6.1483e-02,\n",
      "         6.9577e-02,  3.7162e-02,  1.9369e-01,  3.3612e-02,  4.7781e-02,\n",
      "         2.3091e-01,  1.6431e-01, -1.9461e-04,  1.8133e-01,  1.9096e-01,\n",
      "         6.3822e-02,  3.2990e-02,  2.0852e-01,  1.2595e-01,  1.6865e-01,\n",
      "        -4.0514e-03,  7.6880e-03,  4.7689e-02,  4.3005e-02,  8.3777e-02,\n",
      "         1.4147e-01,  1.0895e-01,  7.2351e-02,  2.4270e-01,  1.0548e-01,\n",
      "         2.3944e-02,  2.8155e-02,  1.1009e-01,  1.0240e-02,  1.4121e-01,\n",
      "         1.0816e-01,  7.9883e-02,  1.4670e-01,  1.0656e-01,  4.2988e-02,\n",
      "         1.6987e-01,  1.1432e-01,  3.6400e-02,  1.3290e-01,  1.0883e-01,\n",
      "         2.0529e-01,  9.6901e-02,  1.1936e-01,  8.8316e-02,  1.4402e-01,\n",
      "         3.8126e-02,  6.2681e-02,  8.4061e-02,  1.6598e-01,  1.7039e-02,\n",
      "         9.8444e-02,  5.4016e-02,  3.5900e-02,  1.8358e-01, -1.0723e-02,\n",
      "         1.3999e-01, -2.0335e-03,  1.6825e-01,  1.6100e-01,  1.4233e-01,\n",
      "         1.4655e-01,  8.0291e-02,  5.5363e-02,  1.0102e-01,  9.1597e-03,\n",
      "         2.4408e-01,  7.3197e-02,  9.5493e-02,  7.9612e-02,  2.3602e-01,\n",
      "         1.2340e-01,  1.6047e-01,  1.6605e-01,  7.2681e-02,  1.8990e-01,\n",
      "         1.2060e-01,  2.0849e-01,  5.2438e-01, -3.2082e-02,  4.2851e-01,\n",
      "        -1.2083e-01,  2.5485e-01,  6.2971e-02, -1.0479e-01, -2.7499e-01,\n",
      "         1.7480e-01,  5.8841e-01, -3.0900e-01,  5.9652e-01,  5.6454e-02,\n",
      "        -1.5788e-01,  2.7375e-01,  4.1371e-03,  1.6940e-02, -1.7297e-01,\n",
      "        -1.3016e-01,  2.6667e-02,  9.8233e-02,  3.1353e-01,  5.3724e-01,\n",
      "        -1.2915e-01,  3.4592e-01, -1.6367e-01, -3.5036e-01, -7.0734e-02,\n",
      "         9.5431e-02,  3.9279e-01,  3.6083e-02,  8.3970e-02, -1.6911e-01,\n",
      "         2.5009e-01, -1.3896e-01, -2.6248e-01,  1.3691e-01, -1.4416e-02,\n",
      "         4.6228e-02, -1.3812e-01,  5.5901e-02,  1.0800e-01, -1.3352e-01,\n",
      "        -2.2711e-01,  5.6771e-02, -8.5163e-02,  5.9584e-02, -2.6556e-01,\n",
      "         5.9445e-02,  2.4268e-01,  1.0111e-01, -1.0022e-01,  4.7092e-02,\n",
      "         4.1625e-01, -2.0535e-01, -2.1664e-01,  1.6537e-02,  9.0902e-02,\n",
      "        -2.4028e-02, -5.4081e-02,  2.0000e-02,  4.4138e-02, -3.1951e-01,\n",
      "        -1.9665e-01, -3.2552e-02, -1.8461e-01,  2.9899e-01, -1.0730e-01,\n",
      "         3.8184e-01,  5.2159e-01, -1.3660e-01,  1.0895e-03, -9.1173e-03,\n",
      "         1.0323e-01, -1.7254e-02,  9.8261e-02,  3.7854e-01, -5.2087e-02,\n",
      "         2.8291e-01,  3.5383e-02,  5.5461e-01,  3.8215e-02,  3.7171e-01,\n",
      "        -6.4947e-02,  3.0397e-02,  5.9757e-01, -9.8127e-02, -3.6125e-01,\n",
      "         5.4028e-03,  2.2991e-02,  1.6992e-01, -2.5271e-01, -7.9225e-03,\n",
      "        -1.6707e-01,  3.8292e-02,  1.1165e-01,  3.5423e-01, -2.1782e-01,\n",
      "        -2.0317e-03,  3.5606e-01, -2.8353e-01,  9.5729e-02, -8.9087e-02,\n",
      "         6.4328e-02,  1.0073e-01, -7.1570e-02, -2.2952e-01,  1.0130e-01,\n",
      "        -1.6118e-01, -1.8305e-01, -1.5717e-01,  9.3998e-02,  1.8219e-01,\n",
      "        -1.4383e-01,  1.4020e-01,  4.0535e-01,  4.2035e-01,  2.2604e-02,\n",
      "         3.2634e-01, -2.1308e-01,  1.0214e-01,  5.5379e-01,  1.0037e-01,\n",
      "        -1.8226e-01,  4.9271e-01,  4.1990e-01,  4.2009e-02,  4.5096e-02,\n",
      "         1.5765e-01, -1.0746e-01, -3.5376e-02,  4.4924e-01,  1.0183e-01,\n",
      "        -1.0026e-01, -1.2614e-01,  9.2977e-02,  6.8350e-02,  2.4941e-01,\n",
      "         7.7884e-02,  7.1408e-02,  4.6089e-03, -4.4059e-02, -1.8317e-01,\n",
      "        -2.2366e-01,  3.4263e-01, -4.2473e-03, -3.0434e-01,  2.4397e-01,\n",
      "         5.7962e-02,  3.1409e-01,  4.0819e-01,  3.9060e-01,  6.1994e-02,\n",
      "         8.5228e-02, -2.7932e-01,  5.3469e-02,  2.6470e-01,  4.0195e-02,\n",
      "         4.0327e-01,  8.3872e-02, -2.6014e-01,  4.5871e-01,  4.1043e-01,\n",
      "         1.8211e-01,  1.8228e-01,  9.9704e-02,  1.9412e-01,  4.6013e-01,\n",
      "         1.6483e-03, -2.2247e-02,  1.0391e-01, -8.2395e-02,  4.3800e-01,\n",
      "         8.2547e-02,  1.4556e-01, -1.8401e-01,  4.7355e-01,  9.9455e-02,\n",
      "         3.1995e-01, -3.3158e-01, -1.2726e-01,  9.2042e-02,  4.7875e-01,\n",
      "         2.9297e-01,  2.1263e-02,  8.7173e-02,  4.3325e-01,  2.8000e-01,\n",
      "         2.8864e-02,  1.1937e-01, -2.9991e-01,  1.3337e-01,  4.0735e-02,\n",
      "         1.5150e-01, -1.7913e-01,  8.7352e-02, -2.6677e-01,  1.4062e-01,\n",
      "        -4.7012e-02,  6.0315e-01,  4.2032e-01,  4.8160e-01,  1.5859e-01,\n",
      "         1.1147e-01,  8.4455e-02,  2.6991e-01,  5.3446e-01, -2.7343e-01,\n",
      "        -4.3189e-01,  3.8265e-02, -2.9259e-01, -1.6635e-01, -7.8558e-02,\n",
      "         1.0490e-01,  3.3566e-01, -1.0647e-01, -4.8903e-02,  4.3097e-02,\n",
      "        -3.0002e-01,  2.4565e-01,  4.2406e-02, -2.8657e-01,  2.6322e-01,\n",
      "         6.5922e-02, -2.4206e-01,  3.6241e-01, -9.5544e-02,  8.2772e-02,\n",
      "        -1.6754e-01,  1.6301e-01,  4.4169e-02,  2.6950e-01, -3.7573e-02,\n",
      "        -3.0038e-01,  3.2266e-03, -4.5451e-01,  1.7100e-01, -1.3880e-01,\n",
      "        -1.3375e-01, -6.1969e-02, -1.2181e-01, -5.5806e-02,  3.6447e-01,\n",
      "        -1.0974e-02, -5.7751e-02, -8.6884e-02,  3.5960e-01, -3.0225e-01,\n",
      "        -6.1927e-02,  1.6708e-01,  1.4031e-02, -5.1701e-02,  1.3002e-02,\n",
      "         1.1020e-01,  3.2438e-02,  1.5515e-01, -8.2782e-02, -1.6208e-01,\n",
      "         1.6360e-02,  9.0841e-02,  3.3271e-02,  1.0039e-01, -8.0937e-02,\n",
      "         1.5795e-01,  1.3519e-02, -1.1198e-02, -1.3518e-01, -8.1765e-02,\n",
      "         5.8646e-03, -1.1847e-01,  1.6196e-01,  1.8067e-01,  5.1269e-02,\n",
      "         7.8330e-02, -4.5504e-02,  2.3755e-02,  2.5310e-02,  5.8285e-03,\n",
      "         5.9749e-02,  2.1253e-01,  5.5093e-02, -2.5413e-02, -1.7635e-01,\n",
      "        -1.1398e-01, -1.2013e-01, -4.4932e-02, -5.1809e-02,  2.4481e-03,\n",
      "        -1.3435e-01,  9.8246e-02,  6.6294e-02,  1.1997e-01, -7.1711e-02,\n",
      "         1.3538e-01, -5.3057e-02, -1.3434e-01,  6.6367e-02,  2.9517e-01,\n",
      "         1.0917e-01, -1.8556e-01,  5.4792e-02, -1.6002e-02,  9.9100e-02,\n",
      "        -7.1549e-02,  1.2592e-01,  4.6698e-02,  4.5820e-02, -1.3921e-01,\n",
      "         2.2070e-01, -2.5185e-02,  3.7596e-02,  1.5097e-02,  3.1857e-02,\n",
      "         4.4286e-02, -1.4780e-01, -1.9180e-02, -3.5872e-02, -3.7795e-03,\n",
      "         1.2211e-01,  5.9351e-02,  2.8363e-02,  2.6631e-01,  1.0125e-01,\n",
      "        -2.2542e-01, -5.0407e-02,  1.1743e-02,  5.1669e-02,  7.8233e-02,\n",
      "        -2.3560e-02,  1.9056e-01,  1.3276e-01,  1.6037e-01, -1.2470e-02,\n",
      "         2.3532e-01, -1.8797e-02,  1.5799e-01, -6.2783e-02, -2.8276e-02,\n",
      "         1.2550e-02, -1.2767e-01,  5.6990e-02,  9.2878e-02,  8.0669e-02,\n",
      "        -3.2866e-02, -9.2758e-02,  1.6775e-01,  1.4324e-01,  6.1025e-02,\n",
      "        -2.1268e-02,  1.4363e-01, -4.3125e-02,  1.0303e-01, -1.5929e-03,\n",
      "        -4.3426e-02,  1.0651e-02,  7.9123e-02,  2.3302e-01, -2.8744e-02,\n",
      "         2.2377e-01,  4.0112e-02,  1.1005e-02,  1.5846e-02, -1.7741e-01,\n",
      "         2.7284e-02,  3.4806e-02, -2.7236e-01,  5.8683e-02, -6.9084e-02,\n",
      "         1.7421e-01, -1.4601e-02,  5.1579e-03, -3.6108e-02, -4.3998e-02,\n",
      "        -1.1383e-01, -1.4571e-01, -1.5465e-01,  1.0351e-01,  5.2667e-02,\n",
      "        -1.1733e-01,  7.7759e-02,  6.8145e-02,  3.2187e-02, -1.4518e-01,\n",
      "        -1.0538e-01,  1.8491e-01, -1.9140e-01,  1.2802e-01,  4.2292e-02,\n",
      "        -3.1071e-02,  5.0488e-02,  7.1560e-02,  3.3503e-02,  3.5112e-02,\n",
      "        -1.4808e-01, -8.0040e-02,  5.1652e-02, -1.0930e-01, -4.0345e-02,\n",
      "         1.9910e-01, -1.6699e-01,  4.8093e-02, -7.0089e-02,  3.6661e-02,\n",
      "         1.1174e-01, -3.6490e-02,  4.9221e-02,  2.8736e-02, -7.3320e-02,\n",
      "        -4.4546e-02,  2.1913e-02,  2.2974e-01,  7.2083e-02, -5.8294e-02,\n",
      "        -1.5017e-02, -8.9599e-02,  1.0408e-02, -1.2054e-01,  6.8431e-02,\n",
      "        -1.0067e-01,  1.4847e-02,  5.0768e-02, -3.9640e-02, -3.5239e-02,\n",
      "        -7.3352e-02, -2.2305e-01,  1.0074e-01,  1.8684e-01,  1.2447e-01,\n",
      "         7.5644e-02, -1.7417e-01, -4.5509e-02, -5.1953e-02, -6.9722e-02,\n",
      "         6.3667e-02, -3.8263e-02, -2.8156e-01,  2.2650e-01, -8.3608e-02,\n",
      "         9.2795e-03,  5.3418e-02, -3.7369e-02,  2.5677e-02,  9.4054e-02,\n",
      "        -1.2595e-01, -5.3322e-03,  1.6585e-02, -9.4191e-02, -6.2813e-03,\n",
      "         8.8932e-02, -1.1083e-01,  1.9229e-02,  8.8917e-02, -2.8573e-01,\n",
      "         2.3206e-02,  1.2040e-01,  1.2189e-02, -3.1053e-02,  7.1796e-03,\n",
      "         9.1775e-02,  3.1148e-03, -6.5733e-02, -8.0544e-02,  3.0188e-02,\n",
      "        -1.4162e-01, -6.1481e-02,  4.6815e-02, -1.2538e-01,  1.1833e-02,\n",
      "         8.4009e-02,  7.8374e-02, -9.2344e-02,  1.6159e-02, -4.6092e-02,\n",
      "        -6.9026e-02,  5.5508e-02, -1.4696e-01,  1.7648e-01,  4.8117e-02,\n",
      "        -9.6608e-02, -4.0169e-02,  2.1314e-01, -1.5532e-02, -7.2548e-02,\n",
      "         1.5854e-01, -2.6293e-01, -4.9941e-02, -1.3941e-02, -1.4599e-01,\n",
      "         9.6411e-02,  2.3929e-01, -9.9567e-02,  4.9922e-01,  6.4767e-02,\n",
      "         1.2511e-02, -5.7167e-02,  2.2493e-02,  1.9123e-01, -3.4368e-02,\n",
      "         7.2432e-02,  2.0909e-01,  3.6743e-02,  3.6824e-02,  2.3636e-02,\n",
      "         1.8825e-01,  7.8465e-02,  1.9119e-02,  4.0036e-02, -2.1750e-02,\n",
      "         1.3617e-02, -6.2651e-02,  1.2871e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "decoder.rnn.bias_hh_l0 Parameter containing:\n",
      "tensor([ 9.9970e-02,  5.5111e-02,  1.5126e-01,  1.3306e-01,  7.4593e-02,\n",
      "         6.8269e-02,  1.3956e-01,  4.6980e-02,  3.4581e-02,  1.9663e-01,\n",
      "         7.4312e-02, -5.1372e-02,  1.5144e-02,  1.9087e-01,  4.3487e-02,\n",
      "         1.8068e-01,  1.8846e-01,  1.7902e-01,  7.0813e-02,  1.8238e-01,\n",
      "         2.5235e-01,  1.5121e-01,  1.4208e-01,  1.0318e-01,  6.7898e-02,\n",
      "         1.2935e-01,  7.5182e-02,  4.8736e-02,  8.6056e-02,  1.3525e-01,\n",
      "         2.0817e-01, -6.7645e-04,  5.9442e-02,  1.1627e-01,  1.0367e-01,\n",
      "         3.8441e-02,  7.1246e-02,  1.4164e-01,  1.3344e-01,  1.4421e-01,\n",
      "         8.6605e-02,  4.1489e-02,  6.6307e-02,  1.0362e-01, -6.5670e-03,\n",
      "         2.5484e-01,  1.1110e-01,  1.4627e-01,  2.1188e-01,  2.2669e-01,\n",
      "         8.6018e-02,  9.3982e-02,  2.2091e-01,  6.6159e-02,  9.4992e-02,\n",
      "         1.6233e-01,  1.5028e-01,  1.8430e-01,  5.2215e-02,  1.6979e-02,\n",
      "         1.1436e-01,  1.3229e-01,  1.6124e-01,  1.4644e-02,  4.5190e-02,\n",
      "         2.4902e-01, -4.4194e-03,  1.4951e-01,  7.7772e-02,  1.7094e-01,\n",
      "         3.0227e-02,  2.1721e-01,  7.9168e-02,  1.2732e-01,  8.0973e-02,\n",
      "         1.5853e-01,  1.2652e-01,  1.7038e-01,  1.0513e-01,  1.6970e-01,\n",
      "         1.2073e-01, -9.7265e-03,  1.5835e-01,  7.8658e-02,  1.6524e-01,\n",
      "         1.0613e-01, -1.7605e-03,  4.7678e-02,  1.0998e-01,  1.0570e-01,\n",
      "         1.6656e-01,  1.7854e-01,  4.5824e-02,  1.0608e-01,  3.7853e-02,\n",
      "         7.8675e-02,  1.7022e-01,  1.1294e-01,  7.9149e-02,  1.1877e-01,\n",
      "         2.0334e-01,  9.5291e-02,  1.1975e-01,  5.2052e-02,  1.3864e-01,\n",
      "         7.1485e-02,  4.9553e-02,  1.2496e-01,  2.3890e-01,  4.6547e-02,\n",
      "         4.1936e-02,  1.0259e-01,  1.7562e-01,  1.7987e-01,  1.3842e-01,\n",
      "         1.2847e-01,  1.6757e-01,  1.0529e-01,  9.7988e-02,  1.1560e-01,\n",
      "         7.8970e-02,  1.9760e-01,  4.6662e-02,  9.4543e-02, -8.2702e-02,\n",
      "         3.6594e-02,  4.8161e-02,  1.3709e-01,  1.7839e-01,  1.7007e-01,\n",
      "         1.6322e-01,  1.8890e-01,  1.5097e-02,  4.6419e-02,  1.8521e-01,\n",
      "         8.8603e-02,  4.5035e-02,  1.3277e-01,  1.6494e-01,  1.4656e-01,\n",
      "         7.6944e-02,  1.4993e-01,  7.7511e-02,  3.2761e-02,  2.6425e-02,\n",
      "         9.2897e-02,  1.7908e-02,  7.5719e-02,  1.8433e-01,  2.6245e-01,\n",
      "         1.3716e-01,  1.0404e-01,  8.3459e-02,  6.3941e-02,  2.2006e-01,\n",
      "         7.3379e-02,  1.4612e-01,  1.4261e-01,  1.2813e-01,  1.2436e-01,\n",
      "         1.6475e-01,  8.2295e-02,  9.2617e-02,  1.0415e-01,  1.0072e-01,\n",
      "         1.3439e-01,  1.9043e-01,  5.6207e-02,  1.0472e-01,  2.0328e-01,\n",
      "         1.3541e-01,  1.9939e-01,  4.7126e-02,  3.8291e-02,  1.7158e-01,\n",
      "         1.2218e-01,  1.4649e-01,  5.7620e-02,  1.8221e-01, -6.0363e-04,\n",
      "         5.3533e-02,  6.8520e-03,  1.5976e-01, -1.7583e-03,  1.0427e-01,\n",
      "         2.1094e-01,  1.1693e-01,  1.1061e-01,  1.7806e-01,  1.8803e-01,\n",
      "         7.5178e-02,  7.3570e-02,  1.6940e-01,  1.8228e-01,  2.2887e-01,\n",
      "         4.9383e-02,  2.1872e-02,  3.8659e-02,  1.0566e-01,  1.5597e-01,\n",
      "         8.3316e-02,  1.5761e-01,  5.9907e-02,  1.8941e-01,  5.6818e-04,\n",
      "         1.2128e-02,  7.6386e-02,  1.1585e-01,  1.3670e-02,  4.5916e-02,\n",
      "         8.8601e-02,  6.0090e-02,  1.5471e-01,  9.3937e-02,  5.3817e-03,\n",
      "         1.5782e-01,  1.1802e-01,  1.2669e-01,  1.8181e-01,  1.2840e-01,\n",
      "         1.4841e-01,  2.9367e-02,  4.0642e-02,  1.4074e-01,  2.0029e-01,\n",
      "         3.4360e-02,  7.4329e-02,  8.0209e-02,  1.3266e-01,  1.0067e-01,\n",
      "         4.9014e-02,  1.0479e-01,  1.0403e-01,  2.0398e-01,  4.2567e-02,\n",
      "         2.2090e-01, -1.0048e-01,  1.8165e-01,  2.4269e-01,  8.9833e-02,\n",
      "         1.5891e-01,  4.2075e-02,  5.2486e-02,  1.0748e-01,  3.9775e-02,\n",
      "         2.8304e-01,  1.0158e-01,  8.9430e-02,  7.3626e-02,  1.5466e-01,\n",
      "         1.3253e-01,  2.4286e-01,  1.9965e-01,  1.1650e-01,  1.2864e-01,\n",
      "         1.5080e-01,  1.7273e-01,  4.4635e-01, -2.1056e-02,  3.9128e-01,\n",
      "        -1.7961e-01,  2.4081e-01,  6.1010e-02, -3.6449e-02, -2.9932e-01,\n",
      "         1.4988e-01,  5.9871e-01, -3.0211e-01,  5.6024e-01,  4.4253e-02,\n",
      "        -8.6905e-02,  3.0575e-01, -2.3546e-02,  3.0028e-02, -1.9923e-01,\n",
      "        -1.2112e-01,  4.8141e-02,  1.5865e-01,  3.9211e-01,  4.8815e-01,\n",
      "        -8.9400e-02,  3.6562e-01, -1.5403e-01, -2.7127e-01, -1.0587e-01,\n",
      "         7.3365e-02,  3.9318e-01, -3.1781e-02,  1.4245e-01, -2.2064e-01,\n",
      "         2.6536e-01, -2.3092e-01, -2.7965e-01,  1.0983e-01, -5.2564e-02,\n",
      "         1.2660e-01, -1.2139e-01,  1.5148e-01,  1.9326e-02, -7.3108e-02,\n",
      "        -2.3819e-01,  2.1921e-02, -1.7505e-01,  1.3051e-01, -1.7360e-01,\n",
      "         9.8606e-02,  3.2906e-01,  1.5832e-02, -1.6810e-02,  4.9474e-02,\n",
      "         4.8739e-01, -2.5842e-01, -1.8558e-01, -3.2575e-02,  8.3913e-02,\n",
      "        -8.3510e-02, -5.4839e-02, -2.3572e-02,  8.1450e-02, -2.9591e-01,\n",
      "        -1.6754e-01,  1.5288e-02, -2.7832e-01,  3.4147e-01, -1.8608e-01,\n",
      "         4.5904e-01,  5.3832e-01, -8.8213e-02, -9.0327e-03, -2.6332e-02,\n",
      "         3.9784e-02, -6.7542e-02,  7.4468e-02,  2.8957e-01, -5.6351e-02,\n",
      "         3.4298e-01,  2.9339e-03,  4.9563e-01,  6.4408e-02,  4.2627e-01,\n",
      "         6.7833e-03,  1.0300e-01,  5.2338e-01, -1.2152e-01, -3.0116e-01,\n",
      "        -2.7346e-02, -1.5860e-02,  1.7717e-01, -1.4395e-01, -3.6478e-02,\n",
      "        -1.7833e-01,  4.6395e-02,  1.1730e-01,  3.7238e-01, -2.9499e-01,\n",
      "         4.2277e-02,  3.5072e-01, -2.5571e-01,  1.7034e-01, -1.5175e-02,\n",
      "         4.4822e-02,  9.9917e-02, -3.5304e-02, -2.2599e-01,  1.0361e-01,\n",
      "        -1.0992e-01, -2.9123e-01, -1.8148e-01,  4.4476e-02,  2.6504e-01,\n",
      "        -1.6218e-01,  1.0214e-01,  3.6654e-01,  4.3885e-01,  5.2577e-02,\n",
      "         2.3219e-01, -2.9541e-01,  1.7798e-02,  4.9952e-01,  7.1453e-02,\n",
      "        -1.1834e-01,  5.7436e-01,  4.5757e-01,  6.0262e-02,  1.1944e-01,\n",
      "         2.0464e-01, -2.5753e-03, -2.4177e-02,  4.0165e-01,  1.5357e-01,\n",
      "        -2.0009e-02, -1.7373e-01,  1.1580e-01,  1.7866e-02,  1.7457e-01,\n",
      "         1.6015e-02,  5.7516e-02, -8.7172e-03, -2.3317e-03, -1.8375e-01,\n",
      "        -2.7147e-01,  3.5174e-01, -4.8385e-02, -2.4031e-01,  2.5535e-01,\n",
      "         8.0089e-02,  2.5600e-01,  4.0135e-01,  3.5220e-01,  4.0100e-02,\n",
      "        -1.3860e-02, -3.0486e-01,  5.0462e-02,  2.8513e-01,  1.4967e-01,\n",
      "         3.9100e-01,  9.1967e-02, -2.6107e-01,  5.2194e-01,  3.3061e-01,\n",
      "         2.3794e-01,  2.1278e-01,  8.9280e-02,  2.3269e-01,  5.4520e-01,\n",
      "         3.2144e-02, -8.3898e-02,  8.3237e-02, -1.8347e-01,  4.0266e-01,\n",
      "         1.1967e-01,  1.2161e-01, -2.0336e-01,  4.2511e-01,  6.0390e-02,\n",
      "         4.0359e-01, -3.3348e-01, -1.2342e-01,  9.3996e-02,  5.0135e-01,\n",
      "         3.2922e-01,  7.3796e-02,  1.3912e-01,  4.8649e-01,  2.4406e-01,\n",
      "        -3.3953e-02,  1.1485e-01, -2.1927e-01,  8.5894e-02,  1.0213e-02,\n",
      "         6.9470e-02, -2.2434e-01,  6.5048e-02, -2.5419e-01,  4.7531e-02,\n",
      "         3.1893e-02,  5.5791e-01,  3.9065e-01,  4.7694e-01,  1.3944e-01,\n",
      "         1.6138e-01,  6.7421e-02,  3.5412e-01,  5.5858e-01, -3.1560e-01,\n",
      "        -4.3720e-01, -2.6567e-02, -3.1163e-01, -1.2039e-01, -3.3516e-02,\n",
      "         1.2818e-01,  3.4613e-01, -7.7463e-02, -6.3318e-03,  3.1958e-02,\n",
      "        -3.1708e-01,  2.6510e-01,  5.1764e-02, -2.2980e-01,  2.1559e-01,\n",
      "        -1.5208e-02, -2.8823e-01,  3.1025e-01, -9.5503e-02, -3.9234e-03,\n",
      "        -9.7324e-02,  1.2425e-01, -7.5453e-03,  2.6391e-01, -3.8948e-02,\n",
      "        -3.3681e-01,  4.2134e-02, -3.9259e-01,  1.2318e-01, -1.3479e-01,\n",
      "        -6.3021e-02, -7.7063e-02, -1.1341e-01,  1.9529e-03,  3.8437e-01,\n",
      "        -2.2373e-02, -6.5299e-02, -2.3580e-02,  3.0021e-01, -3.1948e-01,\n",
      "        -1.0674e-01,  1.0755e-01,  5.8762e-03, -1.0110e-01,  1.7061e-02,\n",
      "         1.4720e-01,  1.4265e-01,  1.2423e-01, -4.4170e-02,  6.1927e-02,\n",
      "        -2.1067e-02,  8.8536e-03, -1.8169e-01,  1.2099e-01, -4.0047e-02,\n",
      "        -7.4381e-03,  2.2407e-02, -6.2846e-02,  1.0970e-01, -1.5035e-02,\n",
      "         3.6807e-02, -1.8363e-02,  1.0536e-01,  1.7288e-01,  8.6685e-02,\n",
      "        -2.5737e-01,  1.1229e-02, -6.3017e-02,  1.1449e-01, -7.6871e-02,\n",
      "         3.2814e-03,  8.6921e-02,  8.8101e-03,  2.6354e-01,  1.3731e-03,\n",
      "         5.2084e-02, -2.2534e-02,  6.0551e-02,  7.3404e-02,  5.5203e-02,\n",
      "         1.3596e-02,  2.2685e-03,  5.3358e-02, -2.3776e-01,  8.4204e-02,\n",
      "        -9.8264e-04, -4.8040e-02,  1.0351e-01,  3.7744e-02, -7.3356e-02,\n",
      "        -8.0144e-04,  7.9458e-02,  2.7200e-03,  5.2110e-03,  4.8644e-02,\n",
      "        -1.7963e-01,  5.2216e-02,  1.6236e-01, -1.2221e-01, -1.6909e-01,\n",
      "        -1.2535e-01,  2.5254e-02,  9.2447e-02,  3.3995e-02,  7.0539e-02,\n",
      "         1.5862e-04,  7.5580e-03, -5.0292e-02, -1.1054e-01,  7.0030e-02,\n",
      "        -3.9887e-02, -1.1617e-01, -1.8084e-02, -2.5974e-01,  7.3907e-02,\n",
      "         3.5938e-02, -3.5085e-02,  4.1919e-02, -2.6689e-02, -7.4957e-02,\n",
      "        -5.8206e-02, -1.7592e-01, -2.5951e-02,  1.9320e-01, -4.2531e-02,\n",
      "         2.2823e-01,  1.3499e-01, -1.2274e-01, -2.8921e-02,  4.6982e-02,\n",
      "        -3.2278e-02, -4.6848e-02, -1.3214e-01,  2.0687e-02,  5.7126e-02,\n",
      "         3.5949e-02, -1.2382e-01,  9.6952e-02,  1.4733e-01, -2.2976e-02,\n",
      "         7.6220e-02, -1.1548e-01, -3.8775e-02,  7.6252e-02,  4.3371e-02,\n",
      "        -7.3977e-02, -1.5422e-01,  8.9090e-02,  2.9867e-02, -1.3877e-02,\n",
      "         1.7275e-02,  1.4640e-01,  1.7089e-01,  7.4920e-02, -2.8352e-02,\n",
      "         1.0450e-02,  1.8887e-01, -6.1975e-02,  2.3006e-02, -8.8415e-02,\n",
      "         1.4003e-01, -4.7143e-02,  2.9057e-02,  5.8941e-02, -1.2003e-01,\n",
      "         1.5248e-01, -8.8713e-02, -1.8491e-02,  1.0218e-02,  5.2313e-02,\n",
      "        -1.3357e-01, -1.6055e-01,  8.2970e-04,  1.7845e-03,  6.0616e-03,\n",
      "        -1.5549e-01,  2.5572e-01, -2.8216e-01,  1.9453e-01, -9.7165e-03,\n",
      "        -8.3383e-02,  2.8250e-02,  1.4718e-03,  1.5906e-01,  6.6983e-02,\n",
      "        -1.2578e-01,  1.0466e-01, -1.2347e-02, -1.6395e-02, -1.2130e-02,\n",
      "         4.5952e-02,  1.5454e-01,  4.1997e-02,  8.4783e-02, -7.2413e-02,\n",
      "         8.5845e-02, -4.5090e-02, -9.7088e-02,  2.1367e-02, -1.6092e-01,\n",
      "        -8.3076e-02, -9.9399e-02, -4.2554e-02,  2.0157e-02,  4.6673e-03,\n",
      "         9.4467e-02, -6.1500e-02, -1.3681e-02,  2.7953e-01,  2.6624e-02,\n",
      "        -1.0660e-01, -1.8828e-01,  3.9245e-02, -4.7166e-02, -9.6001e-02,\n",
      "        -1.1850e-02, -1.8818e-01, -5.6220e-02, -2.3695e-03,  4.3163e-02,\n",
      "         2.0146e-02, -2.2778e-01, -5.4517e-02, -2.5419e-01, -8.4576e-02,\n",
      "        -3.1138e-03, -9.5230e-03, -1.8583e-02, -5.1941e-02,  1.7265e-01,\n",
      "        -3.7690e-02,  2.9593e-02,  1.4038e-02,  1.1675e-01,  3.3743e-02,\n",
      "        -3.0880e-02,  2.5640e-02,  1.7806e-01,  2.5348e-01,  3.0684e-02,\n",
      "         1.0560e-01, -1.1911e-01,  1.2278e-01, -8.9560e-02, -2.0885e-02,\n",
      "        -6.2493e-02,  1.5530e-02,  4.8047e-02,  5.5457e-02,  3.8762e-03,\n",
      "         1.0352e-01, -3.6141e-02, -1.0186e-02, -6.5016e-02,  3.4704e-03,\n",
      "        -2.4191e-02, -1.2443e-01, -1.7920e-02,  1.2068e-01, -1.0288e-01,\n",
      "        -1.2546e-02, -1.4293e-01, -7.2485e-02, -2.7079e-01, -9.0688e-02,\n",
      "         5.8303e-02,  8.6789e-02, -1.1430e-01,  1.3353e-01,  4.0444e-02,\n",
      "         3.7290e-02, -1.7082e-02, -1.2750e-02, -1.3243e-01, -3.0449e-02,\n",
      "         1.7550e-01,  8.4938e-02,  1.8967e-01, -1.2311e-01, -1.1054e-01,\n",
      "         7.3809e-03, -8.6468e-02,  7.7917e-02, -2.6821e-02,  1.1774e-01,\n",
      "         4.8830e-02,  2.5578e-02,  8.1717e-02,  5.9415e-02,  4.2743e-02,\n",
      "         1.3322e-01, -4.2248e-02, -2.1978e-02, -3.2883e-02, -6.7373e-03,\n",
      "        -9.4647e-02,  1.2419e-01,  6.5754e-02, -5.5589e-03, -3.7949e-02,\n",
      "         1.0634e-01, -1.3083e-01, -9.1001e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "decoder.lr.weight Parameter containing:\n",
      "tensor([[-0.1450,  0.1024, -0.0590,  ..., -0.0167, -0.0435,  0.0075],\n",
      "        [-0.2262,  0.3168,  0.2072,  ...,  0.0372,  0.1645,  0.0694],\n",
      "        [-0.0913,  0.0435, -0.0042,  ..., -0.1099,  0.1693, -0.0173],\n",
      "        ...,\n",
      "        [-0.1262, -0.1118, -0.1111,  ..., -0.0128, -0.0244,  0.1144],\n",
      "        [-0.1027,  0.0587,  0.1178,  ..., -0.1450, -0.0016,  0.0162],\n",
      "        [-0.1679,  0.1170,  0.2330,  ..., -0.1822,  0.0500, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "decoder.lr.bias Parameter containing:\n",
      "tensor([-0.0632,  0.0134, -0.0623,  ..., -0.0315, -0.0414, -0.0841],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_parameters():\n",
    "    print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(model.embedding.weight.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2id['<pad>'])\n",
    "cls_optimizer = optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "cls_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(mode, batch_size):\n",
    "    #prepare dataloader\n",
    "    if mode=='train':\n",
    "        dataset = trainset\n",
    "        shuffle = True\n",
    "        teacher_forcing = 1\n",
    "        model.train()\n",
    "    elif mode=='valid':\n",
    "        dataset = trainset\n",
    "        shuffle = False\n",
    "        teacher_forcing = 0\n",
    "        model.eval() #set the module in evaluation mode, only affect dropout, batchnorm\n",
    "    elif mode=='test':\n",
    "        dataset = testset\n",
    "        shuffle = False\n",
    "        teacher_forcing = 0\n",
    "        model.eval()\n",
    "    \n",
    "    batched_dataset = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, \\\n",
    "                            collate_fn=lambda x:collate_fn(x))\n",
    "    #train model\n",
    "    t = tqdm(enumerate(batched_dataset), total=len(dataset)/batch_size)\n",
    "    total_loss = 0\n",
    "    cls_total_loss = 0\n",
    "    ans = []\n",
    "    for i, batch in t: #run batch\n",
    "        batch_text = batch[0].to(device)\n",
    "        batch_label = batch[1].to(device)\n",
    "        output, output_indexes, latent = model(batch_text, batch_text, teacher_forcing=teacher_forcing) \n",
    "        #output=(output_seq_len, batch_size, word num) #latent=(batch_size, hidden_size), requires_grad=True\n",
    "        cls_output = classifier(latent) #cls_output=(batch_size, label_size=2)\n",
    "#         print(latent.shape)\n",
    "#         print(latent.requires_grad)\n",
    "#         print(cls_output.shape, batch_label.shape)\n",
    "        \n",
    "        output_seq_len, batch_size, word_num = output.shape\n",
    "        output = output[1:].view(-1, word_num)\n",
    "        batch_size, output_seq_len = batch_text.shape\n",
    "        batch_text_trans = torch.zeros(output_seq_len, batch_size, dtype=torch.long).to(device)\n",
    "        for seq_p in range(output_seq_len):\n",
    "            batch_text_trans[seq_p] = batch_text[:, seq_p]\n",
    "        batch_text_trans = batch_text_trans[1:]\n",
    "        batch_text_trans = batch_text_trans.view(-1)\n",
    "        \n",
    "        loss = criterion(output, batch_text_trans)\n",
    "#         loss.grad_fn\n",
    "        total_loss += loss.item()\n",
    "        cls_loss = cls_criterion(cls_output, batch_label)\n",
    "        cls_total_loss += cls_loss.item()\n",
    "    \n",
    "        if mode=='train':\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() #based on the (1)current gradient (2)the update rule\n",
    "            cls_optimizer.zero_grad()\n",
    "            cls_loss.backward()\n",
    "            cls_optimizer.step() #based on the (1)current gradient (2)the update rule\n",
    "            \n",
    "        t.set_postfix({'ae loss':total_loss/(i+1), 'cls loss':cls_total_loss/(i+1)})\n",
    "        \n",
    "        for indexes in output_indexes:\n",
    "#             indexes = indexes.type(torch.uint8)\n",
    "            ans.append(indexes.tolist())\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "623it [07:33,  1.37it/s, ae loss=2.7, cls loss=0.093]                                \n"
     ]
    }
   ],
   "source": [
    "ans = run_epoch('train', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "體處理業務範圍，我這裡各位我會公佈，請發言人等待<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "十二月十二月七日，在日本的記者獨聯盟召開記者記者會指出指出日本先生指出，與中村輝夫的，肉體，，休養，表示台表示還台灣<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "道，卡式有有卡式台胞證以來，有關部門依法依法台灣同胞，了萬餘本萬餘本，依法依法保護、便捷、的有了台胞的好事<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "如果如果大家不知道的，，如果如果的說法目還，陳的的但是的國民黨的話，也也的話也是黨念茲來，，黨念茲的立法院，「不」話」，？<eos>說「<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "、魯台會、魯台會、、贛台會、贛台會、、皖台台灣周、、接會、台灣、台灣、、地相繼舉，，台灣台灣青年、和青年在在青年對基層民眾與、地參加的重要經貿各界對<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "正因為是是台灣是對，道德化道德化的政治，如果對管或人人都有政治，但如果回事對政治人物，知道，出一付，在人，在在話<eos>的政治<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "峽導報記者：有有關部門稱經將相關報道組織，“了華族”，了“華族”，對對對對“對“的“、、、華族”、“華族”、活動<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "體赴台方面方面，目前有有消息參加<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "識之士部門部門獻策，特別為一步快實橋，是為了兩岸兩岸同胞<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "言人對此有何評論？第二一個問題，大陸主委，大陸台商台商台商、意見在台商個大陸的台商人，機構，為起將的大陸的的的旅遊的偷漏偷漏<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "”台商在大陸投資興業，同時我們也也也希望許少數人“在大陸賺，，同時“““台獨”，也兩岸關係<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "981年1月，大陸民航主管部門就在經宣佈，大陸民航主管在大陸安排，遇緊急情況，所以通過大陸民航機構降落，起飛，所以民航組織就便利便利，，務，，，，，，，，，，，，，，，，，，，，，，，，，，，，，，，，，，，，\n",
      "由於這些重視，，也也也有於逕<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "台灣在在國際獨立國際上的國際國家，是是是國際社會普遍為獨立法上的國家國家，但是的努力是於國際卻為是是國際社會上被「「的「中華民國」<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "次發佈會上已經很說過了，大陸上個人，，大陸大陸居民赴的是是很的<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "他他所所所的說志工，這是了最萬兒童萬兒童的人權<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "不過和水扁和了兩岸關和兩岸關係的發展行為步，而讓了民意的讓步太多，而日後發展了的行為和<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "望在在，在儘大陸九二共識”基礎上恢快實復兩岸協商，儘儘地大陸同胞包機和大陸居民赴台旅遊合作儘<eos><eos>？？？？？？？？？<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "記者佈：年：今年月8日，台灣人大同胞投資長聯誼會在北京、、、年慶祝大會、是企聯會員及台商、、上海青年工商、、、地個出席<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "岸同胞共同努力，維護兩岸關兩岸關係和平發展的正確基礎，正確方向，維護兩岸關的係和平發展的正確<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "013開放的投資台投資項目、項目個個，投資金額1.17億美元<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "對對對對台灣忠告：「中華與與中華人民共和國一部分」中華，也也沒對方承認中華<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "牠，牠要要狂吠，你來看對視對視，要要你弄清楚的的意見你」，你你你<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "進黨當局，這種慣於一黨恐嚇，，他們一評<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "在隨人顧隨人顧的情況下，在內情況派人士，，發展，減緩泛減緩泛藍新黨化的發展<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "灣青年，特別是基層民眾朋友朋友朋友朋友參與<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "些造的的的事情，大家都都很清楚<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "家父認為數學系畢業後，我可以可以畢業畢業，我我我可以可以賺大錢的科系<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "也有有關部門可以“有稱此舉，進一步對抗大陸抗大陸，請問發言人對此有何看法？<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "台灣與中國中國中國，中國與中國人士會是，，中國，，與常遭中國對威脅，與肆力都<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "已經，我們已經多次表明沒有新，這是新的態度<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "兩岸兩岸同胞合作的交流，包括同胞親情更多發展的、暢敘文化、暢敘親情和親情發展的主題，中共中央台辦、海峽台辦、包括在福建台州椒江區大陳島、湖北、宜城市張自忠將軍紀念館、湖北、、集美）、研學交流交流、江西省交流寧崑崙關戰役舊址等地家海峽省市<eos>家海峽家海峽兩岸交流基地<eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "問題問題，關於這個問題學議題的問題問題問題說：要充棟充棟，當委的的當委的於的「之於「之，委任關係，，可以「之之可以可以建立受人、後」忠人、」<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "至於？我我這樣簡單的話？我看照流照流？？我，身旁的浴缸的話，又加上又浴缸房間浴缸的浴缸的話，又又火大又火大的？？？？？？？？？？？？？？<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "在此社會氛圍下，民進黨的黨外運動正薈萃正薈萃、應運而生<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>？？？？？？？？？？？？？？？？？\n",
      "台台在在台協會，在<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "在他考量與，要要要與國民黨派系交好，自然自然剩下正義連線的頭人<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，本屆文博會將文博會將各類工藝強企工藝、、工藝、、工藝、、工藝、、個，總展覽展位75000平方米，總展覽350035003500個<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "台灣人民的現狀，必須經由台灣人民三百人民人民決定決定決定<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "台灣是台灣的地理位置，地理位置，俗稱台灣的肚臍<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "到此結束，謝謝大家<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "《《近平總書記在《告台灣同胞書》發表40週年紀念會的的講話的的重要舉措，是為台互助的的重要、促進、普惠性涉台政策措施的的<eos>的的的的<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "岸文博會自2008年創辦，，在兩岸兩岸產業、合作合作、促進雙贏、促進兩岸經濟經濟合作、台灣、、的為為台灣重要的平台<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "「總統與「一個統獨」、「總統」總統」，，而「「與「」<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "陳陳儀通過電台聲電台聲明講：蔡人民於列島列島中國版圖編入中國版圖中國版圖台灣台灣政治政治政治中關已經置於民主政治併國家<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "這樣這樣這樣這樣話？？如果，，的說法，就是的有“什麼今夕何夕”的說法？<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "他們台灣論》記者知道去、、、地點、、還到問路，，他他們，請問問路問路，都表示對他們要什麼話有所他們媒體做<eos>話會<eos>？？？<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，這些活動於兩岸關和發展兩岸關係發展的台灣和，應該挺直腰桿，所以邪不壓<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "問題，在在兩岸現來到了進行到了七八百，，更更更更更多的的的問題<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "8年5月，海協會和台灣海基會互會互國共，在在堅持九二共識”基礎上恢復協商協商和協<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n"
     ]
    }
   ],
   "source": [
    "for indexes in list(ans[:50]):\n",
    "    sen = \"\"\n",
    "    for w_id in indexes[1:]:\n",
    "        sen += id2word[str(int(w_id))]#+\" \"\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "623it [01:38,  6.32it/s, ae loss=6.27, cls loss=0.0824]                              \n"
     ]
    }
   ],
   "source": [
    "ans_valid = run_epoch('valid', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9年，我們的《告台灣同胞書》發表40週年紀念會上，我們貫徹十九大《告台灣同胞書》的重要講話，在十九大40週年紀念會的重要講話和支援的重要舉措<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "道，2008年到對兩岸交流的交流合作對兩岸人員往來越多的限制、限制了兩岸交流；對兩岸的人員往來對於社會文化、社會發展的交流與合作的局面<eos>了<eos>的<eos><eos><eos><eos><eos>的<eos><eos><eos><eos><eos><eos><eos><eos>的<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "續進一步促進兩岸經濟文化交流合作、促進的經濟文化交流合作，為台灣同胞來大陸學習、工作、生活提供更多的便利，積極推動兩岸青年的交流合作、惠及台胞來大陸學習、工作的政策措施<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "胞交流合作經受了經受著密切，近年來兩岸人員往來，給兩岸交流基地的規模持續增長了，在台舉辦<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "8年，在“三通”、“三通”，不斷優化營商環境的基礎上，不斷優化營商環境，同時也出台“31條措施”實施細則，取得新進展<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "018，11月11月，11月1日為2070.6億美元<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "部統計，大陸共批准批准投資項目4765，大陸批准台資項目4765個，同比增長7.9%；大陸投資項目4765個，同比增長7.9%；大陸投資項目；實際項目4765個；同比增長26.8%；台投資項目<eos>；同比增長49.1%<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "7、海峽、廣西、廣西、廣西、廣西、廣西、廣西等新台幣赴台旅遊，為台商提供新的發展機遇<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "極組織台商台企參與“一帶一路”、新秩序、新秩序、新秩序、新秩序、新秩序的宗旨，與“一帶一路”、新南向發展與新秩序政策<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "去年，國台辦發言人就台灣地區選舉就此事表明瞭態度了<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "問題，我再證實<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "次正告民進黨當局上台以來，“九二共識”，反對“台獨”分裂活動，煽動兩岸交流合作，不斷煽動兩岸交流合作、破壞兩岸關係和平發展的局面，都必將遭到兩岸民眾交流<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，我還要點回點回點回<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "來，我們堅持“九二共識”、反對“台獨”、堅持“九二共識”的是對台的方針<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "們再次主張全面全面全面，推動兩岸交流合作，我們一直秉持“兩岸一家親”理念，不排除“兩岸一家親”的理念，不可能進行了“兩岸一家親”理念，這是兩岸同胞帶來了實實在的利益<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "次講過，大陸有關方面正在積極推動，打擊犯罪方面一直保持密切，切實保障大陸有關方面高度重視<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "7年9月底，大陸累計減免關稅，對台資企業累計減免關稅；減免關稅；對台累計減免關稅<eos>億元人民幣<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "2002年到，大陸對台灣出口農產品年5月底的出口億美元，為了大陸出口農產品外銷的出口億美元<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，由於服務貿易協議是由ECFA的協議，由於服務貿易協議的ECFA後續協議商談，簽署ECFA後續協議簽署ECFA後續協商的協議<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "8年以來，國共兩黨在堅持“九二共識”、反對“台獨”共同政治基礎上，加強交流對話，推動兩岸關係和平發展，推進兩岸同胞共同維護<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "係和平發展、維護兩岸關係和平發展的局面和人士在堅持“九二共識”的基礎上，反對“台獨”、堅持“九二共識”的共同政治基礎之上，都可以保持著經常性的聯繫<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "沒有出路，搞“台獨”分裂<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "多次表明，一個中國原則，在台灣社會都不存在任何形式的基礎上，任何政黨、都願意積極的立場<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "問題，“九二共識”是兩岸關係和平發展的政治基礎，我們堅持體現了一個中國原則的基礎上的“九二共識”，共同政治基礎的協商談判要討論<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "胞是一家人，和台灣同屬一個中國，大陸都是“國與國”<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "岸對兩岸關係發展的問題，就會在兩岸關係發展中就會談<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "年以來，我們秉持“兩岸一家親”理念，為兩岸同胞的政策措施，為廣大台灣同胞特別是廣大台灣同胞分享大陸發展機遇，為兩岸同胞特別是“一帶一路”沿線推出惠及台胞措施<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "來，對台灣青年來大陸就業、創業、就業、創業的是，有的說，我們對此有幫助，請發言人介紹了他們的政策<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "：如果“一邊一國”“一邊一國”“一邊一國”“一邊一國”、“兩岸一家親”理念，我們對於“台獨”理念，是為什麼理念，請您對於“政治、親”理念，對於“一邊一國”的理念<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，“綿綿用力、久久為功”，兩岸同胞攜手同心，不斷擴大兩岸同胞，攜手發展<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "已經多次重申，我們的對台大政方針是明確的，我們一貫的、一貫的立場<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "要，如果民進黨當局和“台獨”勢力來會有一些勢力來看，他們的“台獨”勢力來會有一些勢力的一些勢力來進行一些“武統”的逼出來會的影響<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "要再次要穩定，要把台灣地區和台灣地區的關係<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "透法”是“台灣同胞的利益，是一部不折不扣的“惡法”，鉗制台灣同胞的利益福祉是兩岸同胞的共同利益<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "惡法”文化和文化、許能交流，企圖阻擋不了兩岸同胞要交流合作的共同願望<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "隨著兩岸的人員往來，隨著兩岸同胞共同努力，隨著兩岸同胞越來越多的、搞“台獨”分裂活動，有越來越多的、親情和親情與大陸同胞利益福祉<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "對於《海峽西岸經濟區》”實施了，依法維護台灣同胞投資保護法》，對於是基層民眾的合法權益和保障台胞合法權益<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "的台灣同胞投資保護法》，國台辦公室和《關於支援台資企業和台灣同胞投資保護法》，受到了台灣同胞的投資環境，也會受到台灣同胞的投資環境和幫助<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "強調，兩岸關係和平發展的是要和兩岸關係的基石，堅持一個中國原則是“九二共識”的基礎上，台灣方面可以堅持“九二共識”的共同政治基礎<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "問題，兩岸之間還存在了一些政治分歧的問題，在於兩岸關係發展的問題，也會充分體現了一個中國原則，在我們對中國的政治基礎上，我們都會在一個中國原則<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "第二個問題，就說，都是非常的，就像你所說的，就是支援中國原則，就不打中和平<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "你提到的“一邊一國”，我們已經說是“台獨”<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "認是認是，我看別的問題都非常清楚<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "問題，這樣的媒體終都說了，它的媒體終也都有了很多現象，甚至於此<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "”，民進黨的“台獨”勢力和勢力的勢力，如果製造“台獨”勢力的勢力，如果製造兩岸敵意，再加上黨派<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "問題，台灣是中國的一部分，台灣當局也是國際社會普遍奉行一個中國原則來處理台灣<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "國原則是中國同在國際社會的普遍共識和國際社會的普遍共識，也是國際社會的普遍共識<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "當局不僅耽于耽于耽于耽于事實，耽于耽于耽于耽于，耽于耽于耽于耽于耽于事實，“春夢”<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "你說，你的說話，如果你說，“31條措施”，進一步把台灣居民的“惡法”，就像“一帶一路”的情況<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "心實意台灣青年給他們，給他們和發展機遇，在他們發展兩岸關係發展，他們損害他們的利益和福祉<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "們認為，當前的是兩岸民間交流和基層交流的是我們也是我們一貫的，就是我們鼓勵和鼓勵兩岸民間交流的基層交流、不會斷、基層交流<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "間，要在國際上頻繁進行“台獨”勢力的政治基礎，對兩岸同胞感情，我想，對台灣同胞的利益<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "台灣在大陸赴台旅遊的事情，是台灣當局發生赴台旅遊的變化<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，大家希望台灣當局應該採取各種措施，儘快給台灣當局儘快給放寬去<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "台灣媒體的報道，大陸配偶的身份證，大陸有關主管部門的身份證，對此沒有二話<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "次表達過，國共兩黨和長期堅持“九二共識”，反對“台獨”，共同推動兩岸交流合作，為促進兩岸關係和平發展，為了促進兩岸關係和平發展<eos>了重要貢獻<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "我們主張與台、頑固堅持“九二共識”、反對“台獨”、反對“台獨”的共同政治基礎，加強溝通和人士保持溝通<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "空航空公司是由航空公司航空公司通過了每週班班，其中大陸航空公司是242班，台灣警方從事班<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "陸主管部門和有關主管部門正在積極準備，按照相關的方式是按照有關的運輸工作，符合兩岸同胞的往來和民眾進行準備<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "Taiwan的發言，我不作評論<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "我們是台灣人民的主張，我們堅持一個中國政策<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "黨以來，我們秉持“九二共識”，順應了一系列促進兩岸一家親”的理念，為了一系列惠及廣大台灣同胞的發展，特別是為了一系列惠及廣大台灣同胞的政策措施<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "位記者長期兩岸經貿交流會上，我了解的情況，由兩岸航空公司的航空公司來進行一些資訊的情況<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "問題，台灣陸委會選舉的新形勢表示，表明台灣要繼續決定<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "一年來，我們認為，在台曲折中不斷前行，是有任何製造業，但是要有的需要，只要是對台方針、和客觀能力，但是大家都是在地有任何，但是和地方是客觀需要，但是大家都是一百分<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "家媒體朋友們，我在這裡向各位介紹了，你們也有記者朋友們了解到這裡，包括兩岸媒體的朋友在春節期間工作與媒體報道、闔家的媒體報道<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "別邀請領保領保領保領保領保了港澳台地區楊舒、社區主任王志偉、王志偉和旅遊部王志偉、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、管理司、滿宏衛、管理司、滿宏衛等地滿宏衛管理司、滿宏衛等地滿宏衛\n",
      "記者：“26條措施”第25條，在台灣同胞參評第14條措施”第14條，請進一步採取台灣同胞在內的相關規定和協助<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "息為台胞返鄉總共處理保護工作提供協助，協助協助內辦理了領事保護協助，協助協助有限公司<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "台胞的台胞往來，我們高度重視，做好各種方式，依法辦案<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "灣同胞通過同胞提供協助，意外事故意外事故還有意外事故及其協助，可以向意外事故及其協助當幾種或其他國家安全渠道為什麼渠道提供協助，協助他們是人之常情<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "撥打撥撥打撥的大熊貓是+86-10-10-----------------------------------------------，是在台北的備用<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "”是下載“港獨”APPAPP，12308�12308熱線�12308熱線�堻�12308熱線，通過“一鍵求助”或者是好事<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "碼公駐外在駐外駐外可以通過，我也可以通過駐外網站的消息查詢<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "是以“小三通”微信公眾號活動的相關活動，都是媒體進行媒體的接線員和媒體進行相關的資訊<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，我們也看到台灣同胞的領事服務網和領事服務網我們可以通過“領事直通車”微信公眾號的“領事直通車”，我們會以各種形式的“團團”在“台灣同胞提供的領事直通”，我們也發佈的相關政策<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "：台灣青年來大陸就讀提供更多，為台灣青年來大陸學習更多的機會<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "7年7年大陸居民開放，大陸高校就讀的台灣學生在大陸高校就讀“31條”為了5年7年，大陸學生在大陸就業許可證到大陸，為台灣同胞提供同等待遇<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "7年，大陸高校就讀台灣居民，教育部又被允許、數學、數學等“學測”成績來達到台灣居民赴台申請，請發言人介紹一下今年1月1號開始的台灣居民來大陸讀<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "為了台商子女大陸學生和大陸學生學生大陸學生學生的需求，為台商子女學校提供了大陸學生的高校學生在大陸高校學校的台商提供服務，大陸學生棒球聯賽的機會和台商提供服務的機會<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，台灣學生報考大陸高校的台灣學生在大陸高校畢業，台灣學生報考大陸高校就讀的台灣學生在大陸高校<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "台灣方面的情況，他們到2016年的時候，大陸和台灣的“團團”，“中校園的中校園的中校園的中校”，對於“三通”，就像大陸對台灣的人和這些樣子<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，從2013年大陸高校學生的生產經營，優化環境和台灣學生提供更多的便利，大陸的需求和台灣同胞來大陸學習，更多的大陸學習、就業的機會和權益，更大的環境和大陸的發展機會<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "播電視總台國廣記者：“26條措施”第14條措施，請您介紹相關的具體情況在具體的相關情況：請您介紹相關情況<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "：關於為台灣同胞的政策措施就是大陸同胞在大陸的學習措施，為台灣同胞在大陸學習、就業的創業待遇<eos><eos><eos><eos>的發展<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "9年，中辦、國辦印發了《關於支援福建省加快建設海峽西岸經濟區的若干意見》，包括涉台民事管理的意見》，包括涉台民事管理辦法》的《關於支援福建省的意見》，在涉台民事民事民事管理暫行辦法》的《關於職稱評審<eos>的意見》<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "台的“31條措施”在大陸的銷售，已經向台灣同胞的需求、工作、創業、就業、生活的條件，包括台灣居民在大陸的科研機構都可以享受更便捷的、級別等方面提供服務的條件<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "意到你說和“31條”在大陸參加職稱，大陸同胞同等同等的待遇，是台灣同胞在大陸參加職稱評審，包括台灣同胞在大陸的專業技術工作的政策和支援<eos>的政策<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "已經有關部門已經通過了台灣同胞在內的職稱評審，包括台灣同胞在內的職稱評審，包括台灣同胞在內的職稱評審<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，我們一直在積極推動台灣同胞的政策措施，為他們提供更好的發展機遇<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "記者：我們注意到“26條措施”中第25個別的第25條，我們支援台資企業與大陸文創園區、可參地的人、可參文化、工業、可參的技術標準、工業等地設計等<eos><eos>的<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "：隨著隨著的文化產業發展，也是由文化產業發展的機遇，文化產業發展機遇，文化產業發展的機遇，也就經濟發展的新形勢下了重要的作用<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "意與台灣同胞分享大陸發展機遇的發展機遇，台灣同胞分享大陸發展的機遇和文化產業發展<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "我們支援支援，在積極推動，為台灣同胞在積極推動，為台灣同胞提供更好的條件<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "業在閩和科研院所就業創業、就業創業基地和示範點的開發、文創園區等活動，包括台灣地區設立省等省，以及農業機構園區等省和國有省等省，在內舉辦了閩設計、農業、農業、文創、農業、農業等領域<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "條措施”出台的細化和支援，為台灣同胞來大陸學習更多的便利，台灣同胞來大陸學習與發展的機遇和獲得感<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "文化、的文化、文化、教育，我們願意向台灣優質農產品、優質農產品、創業、就業、創業、提供服務<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "此外，台灣的文化、教育和基層機構以及台灣人和基層的負責人到台灣同胞參與大陸的文化、教育、文化、廣州、兩岸共同的共同應對機會<eos><eos><eos><eos><eos><eos>的<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "由於7月15日至10日至10位、中國文聯和旅遊部台灣農產品組成的第11屆中國文聯、中國戲劇節，由於中國文聯與台灣農產品農產品由亮相第32屆海峽西岸和旅遊部共同的台灣農產品作品展<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "，在浙江、浙江�堙A�堙A的台胞證有關部門、六項經濟、民生、解難事、緬懷先烈、攜手的好事<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n"
     ]
    }
   ],
   "source": [
    "for indexes in list(ans_valid)[:100]:\n",
    "    sen = \"\"\n",
    "    for w_id in indexes[1:]:\n",
    "        sen += id2word[str(int(w_id))]#+\" \"\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgim_attack(input_indexes, output_indexes, label, batch_size): #model=dis_model, origin_data=latent\n",
    "    label = 1-label\n",
    "    origin_data = model.encode(input_indexes) #get latent\n",
    "    dis_criterion = nn.CrossEntropyLoss(size_average=True)\n",
    "    \n",
    "    step_output = { i:[] for i in range(batch_size)}\n",
    "    for epsilon in [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]:\n",
    "#         print(epsilon)\n",
    "        it = 0\n",
    "        data = origin_data\n",
    "        while True:\n",
    "            data = data.clone().detach()  #(batch_size, seq_length, latent_size)\n",
    "            data.requires_grad = True\n",
    "            cls_output = classifier.forward(data)\n",
    "            loss = dis_criterion(cls_output, label)\n",
    "            \n",
    "            classifier.zero_grad()\n",
    "            loss.backward()\n",
    "            data_grad = data.grad.data\n",
    "            data = data - epsilon * data_grad\n",
    "\n",
    "            it += 1\n",
    "            epsilon = epsilon * 0.9\n",
    "            _, manip_output = model.decode(output_indexes, data) #manip_output=(batch size, hid size)\n",
    "            for b_i, b in enumerate(manip_output.tolist()):\n",
    "                step_output[b_i].append(b)\n",
    "            if it >= 5:\n",
    "                break\n",
    "    for b in list(step_output.values()):\n",
    "        for indexes in b:\n",
    "            sen = \"\"\n",
    "            for w_id in indexes[1:]:\n",
    "                sen += id2word[str(int(w_id))]#+\" \"\n",
    "            print(sen)\n",
    "    return list(step_output.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fgim(batch_size):\n",
    "    #prepare dataloader\n",
    "    mode='valid'\n",
    "    dataset = trainset\n",
    "    shuffle = False\n",
    "    teacher_forcing = 0\n",
    "    model.eval() #set the module in evaluation mode, only affect dropout, batchnorm\n",
    "    \n",
    "    batched_dataset = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, \\\n",
    "                            collate_fn=lambda x:collate_fn(x))\n",
    "    #train model\n",
    "    t = tqdm(enumerate(batched_dataset), total=len(dataset)/batch_size)\n",
    "    total_loss = 0\n",
    "    cls_total_loss = 0\n",
    "    ans = []\n",
    "    gt = []\n",
    "    for i, batch in t: #run batch\n",
    "        batch_text = batch[0].to(device)\n",
    "        batch_label = batch[1].to(device)\n",
    "        batch_ans = fgim_attack(batch_text, batch_text, batch_label, batch_size)\n",
    "        ans.extend(batch_ans)\n",
    "        gt.extend(batch_label.tolist())\n",
    "    return ans, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans, gt = run_fgim(batch_size=128):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}